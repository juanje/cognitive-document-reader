# Cognitive Document Reader - Especificaciones T√©cnicas

## üß† Prop√≥sito y Visi√≥n

**Cognitive Document Reader** es una biblioteca de Python que simula la lectura de documentos similar a la humana a trav√©s de comprensi√≥n progresiva y s√≠ntesis jer√°rquica. El proyecto aborda dos casos de uso principales:

### üéØ **Usos Principales**
1. **Res√∫menes de Alta Calidad para Lectura/Estudio Humano**
   - Res√∫menes estructurados que preservan el flujo narrativo
   - Mapas conceptuales para mejor comprensi√≥n
   - Rutas de aprendizaje progresivo a trav√©s de documentos complejos

2. **Metadatos Enriquecidos para Proyectos de IA**
   - Datos de entrenamiento mejorados para fine-tuning de LLM
   - Informaci√≥n rica en contexto para sistemas RAG
   - Conocimiento estructurado de documentos para flujos de trabajo de IA

### üèóÔ∏è **Principios de Dise√±o**
- **Lectura Similar a la Humana**: Acumulaci√≥n progresiva de conocimiento imitando la cognici√≥n humana
- **Comprensi√≥n Jer√°rquica**: Comprensi√≥n de documentos en m√∫ltiples niveles (documento ‚Üí secciones ‚Üí conceptos)
- **Minimizar Llamadas LLM**: Estrategias eficientes de agrupaci√≥n, cach√© y reutilizaci√≥n de contexto
- **Configurabilidad**: Todas las configuraciones v√≠a variables de entorno, sin valores hardcodeados
- **Testabilidad**: Pruebas exhaustivas con mocks y fixtures
- **Simplicidad**: MVP enfocado en funcionalidad esencial sin excesos

---

## üèóÔ∏è Est√°ndares de Desarrollo

### Calidad del C√≥digo
- **Anotaciones de Tipo Obligatorias**: Todas las funciones, m√©todos y miembros de clase DEBEN tener anotaciones de tipo usando los tipos m√°s espec√≠ficos posibles
- **Docstrings Completos**: Todas las funciones, m√©todos y clases DEBEN tener docstrings estilo Google explicando prop√≥sito, par√°metros, valores de retorno y excepciones
- **Cobertura de Pruebas**: Objetivo m√≠nimo del 90% de cobertura usando `pytest`
- **Manejo Robusto de Excepciones**: Usar tipos espec√≠ficos de excepci√≥n, clases personalizadas cuando sea necesario, evitar cl√°usulas `except` gen√©ricas

### Gesti√≥n de Prompts
- **M√≥dulo Dedicado**: Los prompts LLM deben estar en m√≥dulos dedicados con versionado
- **Plantillas Reutilizables**: Prompts como plantillas parametrizables y testeables
- **Gesti√≥n de Contexto**: Manejo eficiente de contexto usando estructuras de datos apropiadas
- **Multi-idioma**: Prompts espec√≠ficos por idioma con respaldos

### Rendimiento y Optimizaci√≥n
- **Minimizar Llamadas LLM**: Estrategias de agrupaci√≥n, cach√© y reutilizaci√≥n de contexto
- **Programaci√≥n As√≠ncrona**: Usar `async`/`await` para operaciones I/O bound
- **Estrategia de Cach√©**: Aplicar `functools.lru_cache` y `@cache` para evitar rec√°lculos
- **Eficiencia de Memoria**: Liberaci√≥n adecuada de recursos para prevenir memory leaks
- **Monitoreo de Recursos**: Monitorear uso de recursos e identificar cuellos de botella

### Arquitectura y Dise√±o
- **Responsabilidad √önica**: Cada m√≥dulo/archivo con responsabilidad bien definida
- **Composici√≥n sobre Herencia**: Favorecer composici√≥n sobre herencia
- **Expl√≠cito sobre Impl√≠cito**: C√≥digo expl√≠cito que comunique claramente la intenci√≥n
- **Dise√±o Modular**: Componentes reutilizables e independientes

### Seguridad
- **Validaci√≥n de Entrada**: Validaci√≥n robusta de entradas de usuario
- **Manejo de Datos Externos**: Manejo seguro de datos externos y documentos
- **Informaci√≥n de Error**: Mensajes de error informativos sin exponer informaci√≥n sensible

### Configuraci√≥n y Entorno
- **Variables de Entorno**: Todo configurable v√≠a variables de entorno (.env)
- **Sin Hard-coding**: Sin valores hardcodeados (modelos, temperaturas, etc.)
- **Modelos Pydantic**: Usar Pydantic para configuraci√≥n y validaci√≥n de datos
- **Configuraci√≥n Flexible**: Soporte para .env tanto en modo standalone como m√≥dulo

### Idioma y Documentaci√≥n
- **C√≥digo en Ingl√©s**: Todos los comentarios, nombres de variables y documentaci√≥n en ingl√©s
- **Plantillas Multi-idioma**: Solo prompts/plantillas pueden estar en idiomas espec√≠ficos
- **README en Ingl√©s**: Documentaci√≥n principal en ingl√©s para audiencia internacional

### Estrategia de Dependencias
- **Dependencias M√≠nimas**: Solo dependencias esenciales en MVP
- **Pydantic**: Para validaci√≥n de datos y configuraci√≥n
- **Integraci√≥n LangChain**: Considerar LangChain para gesti√≥n avanzada de prompts (Fase 2+)
- **Bases de Datos Vectoriales**: `faiss`/`chroma` para b√∫squeda sem√°ntica (Fase 3+)
- **Librer√≠as de Rendimiento**: `psutil` para monitoreo de recursos

### Gesti√≥n de C√≥digo (MVP - Simplicidad)
- **Pre-commit Simple**: `ruff format`, `ruff check`, `mypy`, `pytest` antes del commit
- **Commits Convencionales**: Usar formato est√°ndar (`feat:`, `fix:`, `docs:`, `refactor:`) desde el inicio
- **Versionado Din√°mico**: Usando `hatchling` + `hatch-vcs` (sin bumping manual)
- **.gitignore B√°sico**: `__pycache__`, `.env`, `dist/`, `build/`, `.mypy_cache/`, `htmlcov/`

### Pruebas MVP
- **Pruebas Unitarias**: Cobertura b√°sica de funcionalidad core usando pytest
- **Mock de Llamadas LLM**: Pruebas determin√≠sticas sin llamadas reales a modelos
- **Fixtures Simples**: Setup/teardown b√°sico para pruebas
- **Pruebas R√°pidas**: Enfoque en velocidad para desarrollo √°gil

### Desarrollo Amigable con Agentes de IA

#### Modos de Desarrollo sin Llamadas LLM
Para **vibe coding** y desarrollo con agentes de IA que necesitan probar sin costos:

```bash
# Variables de entorno para desarrollo
COGNITIVE_READER_DRY_RUN=true           # Sin llamadas LLM reales
COGNITIVE_READER_MOCK_RESPONSES=true    # Usar respuestas simuladas
COGNITIVE_READER_VALIDATE_CONFIG_ONLY=true  # Solo validar configuraci√≥n

# Flags CLI para pruebas
cognitive-reader --dry-run document.md              # Simular procesamiento
cognitive-reader --validate-config                  # Solo verificar config
cognitive-reader --mock-llm-responses document.md   # Usar respuestas falsas
```

#### Casos de Uso Amigables con Agentes
```python
# Verificar configuraci√≥n v√°lida SIN llamadas LLM
from cognitive_reader import CognitiveReader, ReadingConfig

config = ReadingConfig.from_env()
reader = CognitiveReader(config)

# Solo verificar configuraci√≥n - 0 llamadas LLM
is_valid = await reader.validate_configuration()  # ‚úÖ Seguro para agentes

# Procesar con respuestas simuladas - 0 llamadas LLM  
result = await reader.read_document("doc.md", dry_run=True)  # ‚úÖ Seguro para agentes

# Procesar REAL - COSTOSO, solo cuando sea necesario
result = await reader.read_document("doc.md")  # ‚ö†Ô∏è Hace llamadas LLM reales
```

#### Beneficios para Agentes de IA
- ‚úÖ **Pruebas Sin Costo**: Los agentes pueden probar sin gastar dinero/recursos
- ‚úÖ **Validaci√≥n R√°pida**: Verificar configuraciones instant√°neamente  
- ‚úÖ **Salidas Predecibles**: Respuestas simuladas determin√≠sticas
- ‚úÖ **Amigable con Desarrollo**: Iteraci√≥n r√°pida sin esperas de LLM

#### Casos de Uso Espec√≠ficos para Agentes

**ü§ñ Framework de Pruebas para Agentes:**
```python
# El agente puede verificar instalaci√≥n y configuraci√≥n SIN costo
async def test_cognitive_reader_setup():
    reader = CognitiveReader()
    
    # 1. Verificar dependencias instaladas
    is_available = reader.check_dependencies()  # ‚úÖ Seguro
    
    # 2. Verificar configuraci√≥n v√°lida  
    config_valid = await reader.validate_config()  # ‚úÖ Seguro
    
    # 3. Probar parsing b√°sico con mock
    result = await reader.read_document("sample.md", dry_run=True)  # ‚úÖ Seguro
    
    return all([is_available, config_valid, result.success])
```

**üîß Bucle de Desarrollo de Agentes:**
```bash
# Desarrollo t√≠pico de agentes - SIN llamadas costosas:
export COGNITIVE_READER_DEV_MODE=true

# El agente puede iterar r√°pidamente:
cognitive-reader document.md  # Usa mocks, 0 costo
cognitive-reader --validate-config  # Solo verificaci√≥n de config
cognitive-reader document.md --output json | jq .  # Probar parsing de salida
```

**‚ö†Ô∏è Cu√°ndo NO usar estos modos:**
- Validaci√≥n final de calidad de salida real
- Benchmarking de rendimiento con LLMs reales
- Evaluaci√≥n de calidad final de res√∫menes

### Documentaci√≥n MVP
- **README Simple**: Ejemplos b√°sicos de instalaci√≥n y uso
- **Docstrings Esenciales**: Estilo Google para funciones p√∫blicas  
- **Ejemplos M√≠nimos**: 1-2 ejemplos de uso directo
- **Sin documentaci√≥n prematura**: Enfoque en c√≥digo funcionando primero

### Commits Convencionales desde el D√≠a Uno

Usar formato est√°ndar para commits desde **d√≠a uno**:

```bash
feat: add progressive reading functionality
fix: resolve memory leak in document parser
docs: update README with new CLI options
refactor: extract prompt management to separate module
test: add unit tests for hierarchical summarizer
chore: update dependencies and .gitignore

# Ejemplos con scope (opcional)
feat(reader): implement multi-pass refinement
fix(parser): handle empty sections gracefully
docs(api): add docstrings to public methods
```

**Beneficios inmediatos:**
- ‚úÖ Historial de git m√°s legible y profesional
- ‚úÖ Identificaci√≥n f√°cil del tipo de cambio
- ‚úÖ Preparaci√≥n para futura automatizaci√≥n (changelogs, releases)
- ‚úÖ Est√°ndar de industria sin overhead adicional

---

## üöÄ MVP (Fase 1) - Producto M√≠nimo Viable

### Alcance del MVP
El MVP implementa el ciclo b√°sico de lectura cognitiva con funcionalidad esencial:

#### Caracter√≠sticas Incluidas
1. **Lectura Progresiva Secuencial**
   - Procesamiento en orden de aparici√≥n del documento
   - Res√∫menes inmediatos por secci√≥n
   - Acumulaci√≥n progresiva de contexto

2. **S√≠ntesis Jer√°rquica**
   - Detecci√≥n autom√°tica de estructura jer√°rquica
   - S√≠ntesis de secci√≥n padre desde hijos
   - Resumen global del documento

3. **API Dual**
   - Uso como biblioteca de Python
   - CLI standalone con m√∫ltiples formatos de salida

4. **Formatos de Salida**
   - JSON estructurado (para integraci√≥n con otros proyectos)
   - Markdown mejorado (para lectura humana)

5. **Soporte de Formatos**
   - Markdown (.md) v√≠a docling

6. **Soporte de Idiomas**
   - Ingl√©s y espa√±ol (auto-detecci√≥n)
   - Prompts en idioma original del documento

#### Excluido del MVP
- Refinamiento multi-pasada (Fase 2)
- Extracci√≥n de conceptos y glosarios (Fase 2)
- Soporte PDF/DOCX/HTML (Fase 2)
- Mapas avanzados de navegaci√≥n y estructura (Fase 3)
- UI web o API REST (Fases futuras)
- Caracter√≠sticas colaborativas en tiempo real

### Estructura del Proyecto

```
cognitive-document-reader/
‚îú‚îÄ‚îÄ README.md                           # Documentaci√≥n en ingl√©s
‚îú‚îÄ‚îÄ README_es.md                        # Documentaci√≥n en espa√±ol  
‚îú‚îÄ‚îÄ LICENSE                             # Licencia MIT
‚îú‚îÄ‚îÄ pyproject.toml                      # Versionado din√°mico + configuraci√≥n uv
‚îú‚îÄ‚îÄ .env.example                        # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ .gitignore                          # Exclusiones b√°sicas
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ cognitive_reader/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py                 # API p√∫blica
‚îÇ       ‚îú‚îÄ‚îÄ _version.py                 # Versi√≥n auto-generada
‚îÇ       ‚îú‚îÄ‚îÄ 
‚îÇ       ‚îú‚îÄ‚îÄ core/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ progressive_reader.py   # Motor principal de lectura
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ synthesizer.py          # S√≠ntesis jer√°rquica
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ parsers/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ structure_detector.py   # Detecci√≥n de estructura jer√°rquica
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ docling_parser.py       # Parser universal v√≠a docling
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ llm/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ client.py               # Abstracci√≥n LLM (enfoque Ollama)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py              # Gesti√≥n de prompts
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Modelos de configuraci√≥n
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ document.py             # Modelos de datos de documento
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ knowledge.py            # Estructuras de conocimiento
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ utils/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ language.py             # Detecci√≥n de idioma
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ resources.py            # Utilidades de gesti√≥n de recursos
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ cli/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îî‚îÄ‚îÄ main.py                 # Interfaz CLI
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                     # Configuraci√≥n de Pytest
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                       # Datos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ unit/                           # Pruebas unitarias
‚îÇ   ‚îî‚îÄ‚îÄ integration/                    # Pruebas de integraci√≥n
‚îÇ
‚îî‚îÄ‚îÄ examples/
    ‚îú‚îÄ‚îÄ basic_usage.py                  # Ejemplos simples
    ‚îú‚îÄ‚îÄ library_integration.py          # Uso como biblioteca
    ‚îî‚îÄ‚îÄ sample_documents/               # Documentos de prueba
```

### Uso B√°sico del CLI

```bash
# Instalar
pip install cognitive-document-reader

# Uso b√°sico
cognitive-reader document.md

# Con opciones  
cognitive-reader document.md --output json --language es

# Modos de desarrollo
cognitive-reader document.md --dry-run  # Sin llamadas LLM
cognitive-reader --validate-config      # Solo verificaci√≥n de config
```

### Uso como Biblioteca

```python
from cognitive_reader import CognitiveReader
from cognitive_reader.models import ReadingConfig

# Uso b√°sico
config = ReadingConfig(
    model_name="llama3.1:8b",
    temperature=0.1,
    language="auto"
)

reader = CognitiveReader(config)
knowledge = await reader.read_document("document.md")

print(knowledge.document_summary)
for section in knowledge.sections:
    print(f"Section: {section.title}")
    print(f"Summary: {section.summary}")
```

### Modelos Pydantic

```python
from enum import Enum
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field, ConfigDict

class LanguageCode(str, Enum):
    AUTO = "auto"
    EN = "en"
    ES = "es"

class DocumentSection(BaseModel):
    """Secci√≥n individual del documento con informaci√≥n de jerarqu√≠a"""
    model_config = ConfigDict(frozen=True)
    
    id: str
    title: str
    content: str
    level: int
    parent_id: Optional[str] = None
    children_ids: List[str] = Field(default_factory=list)
    order_index: int

class SectionSummary(BaseModel):
    """Resumen de una secci√≥n del documento"""
    section_id: str
    title: str
    summary: str
    key_concepts: List[str] = Field(default_factory=list)

class DocumentKnowledge(BaseModel):
    """Conocimiento completo extra√≠do del documento"""
    document_title: str
    document_summary: str
    detected_language: LanguageCode
    sections: List[DocumentSection]
    section_summaries: Dict[str, SectionSummary]
    processing_metadata: Dict[str, Any]

class ReadingConfig(BaseModel):
    """Configuraci√≥n simplificada de lectura para MVP - enfoque en esenciales"""
    # Configuraci√≥n LLM (modelos probados)
    model_name: str = Field(default="llama3.1:8b")  # Probado mejor para seguimiento de instrucciones
    temperature: float = Field(default=0.1, ge=0.0, le=2.0)  # Bajo para res√∫menes consistentes
    
    # Procesamiento de Documentos (configuraciones esenciales)
    chunk_size: int = Field(default=1000, gt=100)  # √ìptimo para lectura cognitiva
    chunk_overlap: int = Field(default=200, ge=0)  # ~20% overlap mantiene continuidad
    context_window: int = Field(default=4096, gt=0)  # L√≠mite est√°ndar que funciona
    
    # Configuraciones de Rendimiento (simplificadas)
    timeout_seconds: int = Field(default=120, gt=0)  # Timeout razonable
    max_retries: int = Field(default=3, ge=0)  # Conteo est√°ndar de reintentos
    
    # Idioma y Salida
    document_language: LanguageCode = Field(default=LanguageCode.AUTO)
    
    # Modos de desarrollo (amigables con agentes IA)
    dry_run: bool = Field(default=False)  # Habilitar modo dry-run (sin llamadas LLM)
    mock_responses: bool = Field(default=False)  # Usar respuestas simuladas para pruebas
    
    @classmethod
    def from_env(cls) -> "ReadingConfig":
        """Crear config desde variables de entorno con respaldo a defaults"""
        import os
        return cls(
            model_name=os.getenv("COGNITIVE_READER_MODEL", "llama3.1:8b"),
            temperature=float(os.getenv("COGNITIVE_READER_TEMPERATURE", "0.1")),
            chunk_size=int(os.getenv("COGNITIVE_READER_CHUNK_SIZE", "1000")),
            chunk_overlap=int(os.getenv("COGNITIVE_READER_CHUNK_OVERLAP", "200")),
            context_window=int(os.getenv("COGNITIVE_READER_CONTEXT_WINDOW", "4096")),
            timeout_seconds=int(os.getenv("COGNITIVE_READER_TIMEOUT_SECONDS", "120")),
            max_retries=int(os.getenv("COGNITIVE_READER_MAX_RETRIES", "3")),
            document_language=LanguageCode(os.getenv("COGNITIVE_READER_LANGUAGE", "auto")),
            dry_run=os.getenv("COGNITIVE_READER_DRY_RUN", "false").lower() == "true",
            mock_responses=os.getenv("COGNITIVE_READER_MOCK_RESPONSES", "false").lower() == "true",
        )
```

---

## üìà Fases de Desarrollo Futuro

### Fase 2: Refinamiento y Conceptos

#### Nuevas Caracter√≠sticas
- **Refinamiento de Segunda Pasada**
  - Mejora de res√∫menes con contexto global
  - Identificaci√≥n de conexiones profundas
  - Correcci√≥n de inconsistencias

- **Extracci√≥n de Conceptos**
  - Glosario contextual autom√°tico
  - Referencias cruzadas
  - Definiciones en contexto dentro del documento

- **Formatos Adicionales**
  - PDF (v√≠a docling)
  - DOCX (v√≠a docling)
  - HTML (v√≠a docling)

- **Salida Mejorada**
  - Documentos Markdown con res√∫menes estructurados
  - Exportaci√≥n de glosario
  - Metadatos enriquecidos para proyectos de IA
  - HTML

#### API Extendida
```python
# Refinamiento
refined_knowledge = await reader.refine_knowledge(knowledge)

# Extracci√≥n de conceptos
concepts = await reader.extract_concepts(knowledge)
print(concepts.glossary)  # Glosario de t√©rminos
print(concepts.references)  # Referencias por concepto
```

#### Configuraci√≥n Avanzada (Fase 2+)

```python
class AdvancedReadingConfig(ReadingConfig):
    """Configuraci√≥n extendida para caracter√≠sticas avanzadas - Fase 2+"""
    # Configuraci√≥n LLM Adicional
    llm_provider: str = Field(default="ollama")
    validation_model: str = Field(default="deepseek-r1:8b")  # Superior para an√°lisis
    
    # Procesamiento Avanzado de Documentos
    max_section_length: int = Field(default=2000, gt=0)  # Para contexto jer√°rquico
    
    # Configuraciones de Rendimiento (probadas en producci√≥n)
    enable_parallel_processing: bool = Field(default=True)
    max_parallel_tasks: int = Field(default=3, gt=0)  # Paralelismo sin saturaci√≥n
    
    # Estrategia de Cach√© (Fase 3+ cuando se necesite)
    cache_enabled: bool = Field(default=True)
    cache_max_memory_mb: int = Field(default=100, gt=0)  # L√≠mite razonable de memoria
    cache_expiry_hours: int = Field(default=24, gt=0)  # Expiraci√≥n apropiada
    cache_strategy: str = Field(default="hybrid")  # H√≠brido memoria + disco
    
    # Generaci√≥n de Res√∫menes (l√≠mites de tokens optimizados)
    document_summary_max_tokens: int = Field(default=400, gt=0)  # Para documento completo
    section_summary_max_tokens: int = Field(default=200, gt=0)  # Para secciones principales
    concept_summary_max_tokens: int = Field(default=150, gt=0)  # Para conceptos clave
    
    # Controles de Calidad (umbrales validados)
    min_confidence: float = Field(default=0.75, ge=0.0, le=1.0)  # Umbral de calidad probado
    min_coherence_score: float = Field(default=0.6, ge=0.0, le=1.0)  # Validaci√≥n contextual
    max_concepts_per_document: int = Field(default=8, gt=0)  # N√∫mero √≥ptimo de conceptos clave
    
    # Modos de desarrollo adicionales
    validate_config_only: bool = Field(default=False)  # Solo validar config, sin procesamiento
    dev_mode: bool = Field(default=False)  # Habilitar modo desarrollo con todos los mocks
```

#### Herramientas de Desarrollo Profesional (Fase 2)
- **CI/CD Completo**
  - GitHub Actions con matriz de pruebas (Python 3.12, 3.13)
  - Hooks autom√°ticos de pre-commit
  - Dependabot para actualizaciones de seguridad
  - Automatizaci√≥n de releases a PyPI con tags

- **Flujo de Trabajo Git Avanzado**
  - Ramas de caracter√≠sticas y flujo de PR
  - Reglas de protecci√≥n de ramas y requisitos de code review
  - Merge autom√°tico despu√©s de verificaciones de estado

- **Aseguramiento de Calidad**
  - Reporte autom√°tico de cobertura de c√≥digo
  - Benchmarks de rendimiento en CI
  - Escaneo de vulnerabilidades de dependencias (safety)
  - Gates opcionales de calidad de c√≥digo (SonarCloud/CodeClimate)

### Fase 3: Mapas y Navegaci√≥n

#### Nuevas Caracter√≠sticas
- **Mapas Estructurales**
  - Mapa de navegaci√≥n f√≠sica
  - Red conceptual
  - Visualizaci√≥n de flujo de ideas

- **Navegaci√≥n Inteligente**
  - B√∫squeda sem√°ntica
  - Recomendaciones de lectura
  - Rutas de aprendizaje

#### API Extendida
```python
# Mapas estructurales
maps = await reader.create_structural_maps(knowledge)
physical_map = maps.physical_structure
conceptual_map = maps.conceptual_network

# Navegaci√≥n
navigator = knowledge.create_navigator()
related_sections = navigator.find_related("concept")
learning_path = navigator.create_learning_path(["concept1", "concept2"])
```

### Fase 4: Multi-idioma y Optimizaci√≥n

#### Nuevas Caracter√≠sticas
- **Soporte Multi-idioma Completo**
  - Detecci√≥n autom√°tica mejorada de idioma
  - Soporte para idiomas adicionales
  - Traducci√≥n de res√∫menes a idiomas objetivo
  - Prompts optimizados por idioma

- **M√©tricas de Lectura**
  - Calidad del resumen
  - Coherencia narrativa
  - Completitud de extracci√≥n

- **Optimizaci√≥n Autom√°tica**
  - Ajuste de par√°metros por documento e idioma
  - Detecci√≥n de patrones √≥ptimos
  - Mejora continua de prompts

### Fase 5: Integraci√≥n y Exportaci√≥n

#### Nuevas Caracter√≠sticas
- **Integraci√≥n con Bases de Datos**
- **Exportaci√≥n Avanzada**
  - M√∫ltiples formatos (LaTeX, EPUB, etc.)
  - Plantillas personalizables
  - Metadatos enriquecidos para sistemas de IA

### Estrategias de Optimizaci√≥n LLM

#### Minimizaci√≥n de Llamadas
- **Agrupaci√≥n Inteligente**: Agrupar secciones relacionadas en una sola llamada
- **Reutilizaci√≥n de Contexto**: Reutilizar contexto acumulado entre secciones consecutivas
- **Optimizaci√≥n de Plantillas**: Plantillas eficientes que generen resultados consistentes

#### Gesti√≥n de Ventana de Contexto
- **Chunking Inteligente**: Divisi√≥n inteligente respetando l√≠mites de contexto (1000 chars probado)
- **Priorizaci√≥n de Contexto**: Priorizar contexto m√°s relevante para cada secci√≥n
- **Contexto Jer√°rquico**: Usar jerarqu√≠a para optimizar uso de contexto (2000 chars max probado)
- **Estrategias de Respaldo**: Degradaci√≥n elegante cuando se excede el contexto

#### Valores Probados y Optimizados
Basado en experiencia exitosa de `extract-to-train`, usando valores que han demostrado **excelente rendimiento en producci√≥n**:

**ü§ñ Modelos Optimizados:**
- **llama3.1:8b**: Probado mejor para seguimiento de instrucciones y generaci√≥n de res√∫menes
- **deepseek-r1:8b**: Superior para an√°lisis y validaci√≥n de calidad  
- **Temperatura 0.1**: √ìptima para res√∫menes consistentes y fieles

**üìÑ Procesamiento Eficiente:**
- **Tama√±o de Chunk 1000**: √ìptimo para lectura cognitiva - preserva mejor coherencia narrativa
- **Overlap 200**: ~20% overlap mantiene continuidad sin redundancia excesiva
- **Ventana de Contexto 4096**: L√≠mite est√°ndar que funciona confiablemente

**‚ö° Rendimiento Validado:**
- **3 tareas paralelas**: M√°ximo paralelismo sin saturaci√≥n del sistema
- **Timeout 120s**: Tiempo suficiente para operaciones complejas sin colgarse
- **3 reintentos**: N√∫mero √≥ptimo para manejar fallos temporales

**üíæ Gesti√≥n de Recursos (MVP):**
- **Enfoque simple**: Procesamiento directo sin cach√© complejo
- **Eficiencia de memoria**: Limpieza adecuada despu√©s del procesamiento
- **Mejora futura**: Estrategias de cach√© planificadas para Fase 3+

**üéØ Umbrales de Calidad:**
- **Confianza 0.75**: Umbral que asegura alta calidad sin ser demasiado restrictivo
- **Coherencia 0.6**: L√≠mite para validaci√≥n contextual balanceada
- **8 conceptos max**: N√∫mero √≥ptimo de conceptos clave por documento

---

## üèóÔ∏è Arquitectura T√©cnica Detallada

### Componentes Core

#### ProgressiveReader
- **Responsabilidad**: Motor principal de lectura con procesamiento progresivo secuencial
- **M√©todos Clave**:
  - `read_document(file_path, config)`: M√©todo principal de lectura
  - `_process_section(section, accumulated_context)`: Procesar secci√≥n individual
  - `_accumulate_context(section_summary, context)`: Construir contexto progresivo

#### StructureDetector  
- **Responsabilidad**: Detecta estructura jer√°rquica usando docling
- **M√©todos Clave**:
  - `detect_structure(document)`: Extrae secciones jer√°rquicas
  - `_build_section_tree(elements)`: Construye √°rbol desde estructura plana
  - `_identify_section_types(sections)`: Clasifica secciones de contenido vs contenedor

#### Synthesizer
- **Responsabilidad**: S√≠ntesis jer√°rquica desde el m√°s profundo al m√°s superficial
- **M√©todos Clave**:
  - `synthesize_document(sections, summaries)`: S√≠ntesis completa del documento
  - `_synthesize_container_section(section, child_summaries)`: Contenedor desde hijos
  - `_synthesize_content_section(section)`: Resumen de secci√≥n de contenido

#### LLMClient
- **Responsabilidad**: Abstracci√≥n simple de LLM (enfoque Ollama)
- **M√©todos Clave**:
  - `generate_summary(content, context, prompt_type)`: Generar res√∫menes
  - `_handle_retries(operation)`: L√≥gica b√°sica de reintentos

#### PromptManager
- **Responsabilidad**: Gesti√≥n simple de prompts
- **M√©todos Clave**:
  - `get_prompt(type, language)`: Prompts espec√≠ficos por idioma
  - `format_prompt(section, context)`: Formateo b√°sico de prompts

#### DoclingParser
- **Responsabilidad**: Parsing universal de documentos
- **Caracter√≠sticas**:
  - **Soporte MVP**: Markdown v√≠a docling
  - **Soporte Futuro**: PDF, DOCX, HTML v√≠a docling
  - **Detecci√≥n de Estructura**: Extracci√≥n de estructura jer√°rquica
  - **Extracci√≥n de Contenido**: Texto limpio con preservaci√≥n de metadatos

---

## üì¶ Configuraci√≥n del Proyecto

### Dependencias (pyproject.toml)

```toml
[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[project]
name = "cognitive-document-reader"
dynamic = ["version"]  # Versionado autom√°tico desde git tags

# Versionado autom√°tico din√°mico
[tool.hatch.version]
source = "vcs"
tag-regex = "^v(?P<version>\\d+\\.\\d+\\.\\d+)$"

[tool.hatch.build.hooks.vcs]
version-file = "src/cognitive_reader/_version.py"

[tool.uv]
python-version = "3.12"
index-strategy = "unsafe-best-match"

[project.scripts]
cognitive-reader = "cognitive_reader.cli.main:cli"

authors = [{name = "Juanje Ojeda", email = "juanje@redhat.com"}]
description = "Lectura avanzada de documentos con comprensi√≥n progresiva similar a la humana"
readme = "README.md"
license = {text = "MIT"}
keywords = ["llm", "document-processing", "cognitive-reading", "summarization"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers", 
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
]
requires-python = ">=3.12"

dependencies = [
    "pydantic>=2.0,<3.0",      # Validaci√≥n de datos y configuraciones
    "aiohttp>=3.8,<4.0",       # Cliente HTTP as√≠ncrono  
    "click>=8.0,<9.0",         # Framework CLI
    "docling>=2.40,<3.0",      # Parsing universal de documentos (estable actual: v2.43.0)
    "langdetect>=1.0,<2.0",    # Detecci√≥n de idioma
    "python-dotenv>=1.0,<2.0", # Soporte de archivos .env
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0,<8.0",
    "pytest-asyncio>=0.21,<1.0",
    "ruff>=0.1,<1.0",          # Solo ruff para linting y formateo
    "mypy>=1.0,<2.0",
]
```

### Versionado Din√°mico Simple

El proyecto usa **versionado autom√°tico** con tags de git (sin bumping manual):

```bash
# Para crear una nueva versi√≥n:
git tag v0.1.0         # Crea versi√≥n 0.1.0  
git tag v0.1.1         # Release de parche
git tag v0.2.0         # Release menor

# La versi√≥n se auto-genera desde el √∫ltimo tag de git
# No necesidad de editar archivos manualmente ‚ú®
```

**Beneficios MVP:**
- ‚úÖ Sin edici√≥n manual de versi√≥n en m√∫ltiples archivos  
- ‚úÖ Versionado autom√°tico consistente
- ‚úÖ Perfecto para proyectos personales
- ‚úÖ Se integra perfectamente con uv y PyPI

### Gesti√≥n UV

```bash
# Instalar dependencias
uv sync

# Ejecutar pruebas
uv run pytest

# Ejecutar linting
uv run ruff check .
uv run ruff format .

# Verificaci√≥n de tipos
uv run mypy src/

# Uso del CLI
uv run cognitive-reader document.md

# Construir paquete
uv build
```

### Variables de Entorno

```bash
# .env - Configuraci√≥n Esencial MVP
COGNITIVE_READER_MODEL=llama3.1:8b          # Probado mejor para seguimiento de instrucciones
COGNITIVE_READER_TEMPERATURE=0.1             # Bajo para res√∫menes consistentes
COGNITIVE_READER_LANGUAGE=auto

# Procesamiento de documentos (configuraciones esenciales)
COGNITIVE_READER_CHUNK_SIZE=1000            # Balance √≥ptimo contexto/eficiencia
COGNITIVE_READER_CHUNK_OVERLAP=200          # ~20% overlap mantiene continuidad
COGNITIVE_READER_CONTEXT_WINDOW=4096        # L√≠mite est√°ndar que funciona bien

# Configuraciones de rendimiento (simplificadas)
COGNITIVE_READER_TIMEOUT_SECONDS=120        # Timeout razonable
COGNITIVE_READER_MAX_RETRIES=3              # Conteo est√°ndar de reintentos

# Modos de desarrollo (amigables con agentes IA)
COGNITIVE_READER_DRY_RUN=false              # Habilitar modo dry-run (sin llamadas LLM)
COGNITIVE_READER_MOCK_RESPONSES=false       # Usar respuestas simuladas para pruebas
```

---

## üß™ Plan de Pruebas

### Est√°ndares de Pruebas (MVP)
- **Framework**: Pytest con funciones simples
- **Cobertura Objetivo**: 80% cobertura de c√≥digo (realista para MVP)
- **Tipos de Pruebas**: Pruebas unitarias y de integraci√≥n b√°sicas
- **Aislamiento de Pruebas**: Fixtures simples para setup esencial

### Organizaci√≥n de Pruebas (MVP)

```python
# tests/conftest.py - Simplificado para MVP
import pytest
from cognitive_reader.models import ReadingConfig

@pytest.fixture
def test_config():
    """Configuraci√≥n simple de prueba con mocks habilitados."""
    return ReadingConfig(
        model_name="test-model",
        dry_run=True,
        mock_responses=True
    )

@pytest.fixture  
def sample_markdown():
    """Markdown simple para pruebas."""
    return """
# Test Document

## Section 1
Content of section 1.

## Section 2  
Content of section 2.
    """
```

### Categor√≠as de Pruebas

#### Pruebas Unitarias (MVP)
```python
# tests/test_reading.py - Pruebas simples MVP
import pytest
from cognitive_reader import CognitiveReader

def test_config_creation(test_config):
    """Probar creaci√≥n de configuraci√≥n."""
    assert test_config.model_name == "test-model"
    assert test_config.dry_run is True

async def test_basic_reading(test_config, sample_markdown):
    """Probar lectura b√°sica de documento en modo dry-run."""
    reader = CognitiveReader(test_config)
    knowledge = await reader.read_document_text(sample_markdown)
    
    assert knowledge.document_title == "Test Document"
    assert len(knowledge.sections) >= 2
    assert knowledge.detected_language in ["en", "auto"]

def test_environment_config():
    """Probar configuraci√≥n desde variables de entorno."""
    config = ReadingConfig.from_env()
    assert config.model_name == "llama3.1:8b"  # default
```

#### Pruebas de Integraci√≥n (MVP)
```python
# tests/test_integration.py - Pruebas de integraci√≥n esenciales
import pytest
import os

async def test_markdown_processing(test_config, tmp_path):
    """Probar procesamiento completo de archivo markdown."""
    # Crear archivo markdown temporal
    md_file = tmp_path / "test.md"
    md_file.write_text("# Test\n\n## Section\nContent here.")
    
    reader = CognitiveReader(test_config)
    knowledge = await reader.read_document(str(md_file))
    
    assert knowledge.document_title == "Test"
    assert len(knowledge.sections) >= 1

def test_env_config_loading(monkeypatch):
    """Probar carga de configuraci√≥n desde variables de entorno."""
    monkeypatch.setenv("COGNITIVE_READER_MODEL", "custom-model")
    monkeypatch.setenv("COGNITIVE_READER_TEMPERATURE", "0.5")
    
    config = ReadingConfig.from_env()
    assert config.model_name == "custom-model"
    assert config.temperature == 0.5
```

#### Pruebas de Rendimiento (B√°sicas)
```python
# tests/test_performance.py - Validaci√≥n b√°sica de rendimiento
import pytest
import time

@pytest.mark.performance
async def test_reasonable_processing_time(test_config, sample_markdown):
    """Probar que el procesamiento se complete en tiempo razonable."""
    reader = CognitiveReader(test_config)
    
    start_time = time.time()
    await reader.read_document_text(sample_markdown)
    processing_time = time.time() - start_time
    
    # En modo dry-run, deber√≠a ser muy r√°pido
    assert processing_time < 5.0  # segundos
```

---

## üìã Hoja de Ruta de Desarrollo

### Hitos

#### Hito 1: Base MVP
- [ ] Estructura b√°sica del proyecto con uv
- [ ] Modelos Pydantic para configuraci√≥n y datos
- [ ] Parser universal con docling
- [ ] Lector progresivo simple
- [ ] Interfaz CLI b√°sica
- [ ] Pruebas esenciales con mocks

#### Hito 2: Funcionalidad Core
- [ ] Detecci√≥n de estructura jer√°rquica
- [ ] Lectura progresiva secuencial
- [ ] S√≠ntesis jer√°rquica
- [ ] Soporte multi-idioma (EN/ES)
- [ ] Configuraci√≥n completa de entorno
- [ ] Modos de desarrollo amigables con agentes

#### Hito 3: Caracter√≠sticas de Fase 2
- [ ] Refinamiento de segunda pasada
- [ ] Extracci√≥n de conceptos y glosarios
- [ ] Soporte completo PDF/DOCX v√≠a docling
- [ ] Pipeline profesional CI/CD
- [ ] Optimizaciones de rendimiento

#### Hito 4: Caracter√≠sticas de Fase 3
- [ ] Mapas estructurales y conceptuales
- [ ] Navegaci√≥n inteligente
- [ ] Formatos de exportaci√≥n avanzados
- [ ] APIs de integraci√≥n

---

## üìà M√©tricas de √âxito

### M√©tricas T√©cnicas (MVP)
- **Cobertura de Pruebas**: >80%
- **Rendimiento**: <30s para documentos de 50 p√°ginas
- **Uso de Memoria**: <50MB memoria de procesamiento (sin cach√©)
- **Tiempo de Respuesta API**: <200ms para operaciones b√°sicas
- **Eficiencia LLM**: Minimizaci√≥n razonable de llamadas
- **Confiabilidad**: Manejo b√°sico de errores y l√≥gica de reintentos

### M√©tricas de Adopci√≥n
- **Descargas PyPI**: >1000/mes en 6 meses
- **Estrellas GitHub**: >100 en 1 a√±o
- **Issues/PRs**: Actividad consistente de la comunidad

### M√©tricas de Calidad
- **Documentaci√≥n**: Docs completos de API + ejemplos
- **Experiencia de Usuario**: Mensajes de error claros y advertencias √∫tiles
- **Confiabilidad**: <1% tasa de fallo en procesamiento de documentos

---

## ü§ñ Disclaimer de Herramientas de IA

Este proyecto fue desarrollado con la asistencia de herramientas de inteligencia artificial:

**Herramientas utilizadas:**
- **Cursor**: Editor de c√≥digo con capacidades de IA
- **Claude-4-Sonnet**: Modelo de lenguaje de Anthropic

**Divisi√≥n de responsabilidades:**

**IA (Cursor + Claude-4-Sonnet)**:
- üîß Prototipado inicial de c√≥digo
- üìù Generaci√≥n de ejemplos y casos de prueba
- üêõ Asistencia en debugging y resoluci√≥n de errores
- üìö Escritura de documentaci√≥n y comentarios
- üí° Sugerencias de implementaci√≥n t√©cnica

**Humano (Juanje Ojeda)**:
- üéØ Especificaci√≥n de objetivos y requisitos
- üîç Revisi√≥n cr√≠tica de c√≥digo y documentaci√≥n
- üí¨ Retroalimentaci√≥n iterativa y refinamiento de soluciones
- üìã Definici√≥n de estructura educativa del proyecto
- ‚úÖ Validaci√≥n final de conceptos y enfoques

**Filosof√≠a de colaboraci√≥n**: Las herramientas de IA sirvieron como un asistente t√©cnico altamente capaz, mientras que todas las decisiones de dise√±o, objetivos educativos y direcciones del proyecto fueron definidas y validadas por el humano.

---

## üìú Licencia

Licencia MIT - Ver archivo LICENSE para detalles

---

*Esta especificaci√≥n proporciona una hoja de ruta completa para implementar un lector cognitivo de documentos de grado profesional con capacidades de comprensi√≥n similar a la humana.*
