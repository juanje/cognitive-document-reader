# Cognitive Document Reader - Especificaciones T√©cnicas v3.0

> Especificaciones t√©cnicas completas basadas en ingenier√≠a inversa del proyecto implementado

---

## üéØ Resumen Ejecutivo

**Cognitive Document Reader** es una librer√≠a Python que implementa procesamiento cognitivo de documentos que simula los patrones de lectura humana a trav√©s de un algoritmo secuencial multi-pasada con contexto acumulativo y principio de autoridad del texto fuente.

### Prop√≥sito Principal

Generar res√∫menes jer√°rquicos de alta calidad y datasets contextualizados para:
- **Fine-tuning de LLMs**: Datasets que preserven la voz y metodolog√≠a del autor original
- **Sistemas RAG**: Chunks enriquecidos con contexto jer√°rquico y conceptos clave
- **Lectura humana**: Res√∫menes estructurados que respetan el flujo narrativo

### Diferenciaci√≥n T√©cnica

A diferencia de los sistemas tradicionales de fragmentaci√≥n de documentos, implementa:
- **Algoritmo secuencial** que procesa secciones en orden del documento
- **Contexto acumulativo** (padres + hermanos previos) para cada secci√≥n
- **Principio de autoridad** del texto fuente sobre cualquier informaci√≥n contextual
- **Procesamiento multi-pasada** con enriquecimiento contextual progresivo
- **Modelo dual** optimizado para velocidad vs. calidad seg√∫n la pasada

---

## üèóÔ∏è Arquitectura del Sistema

### Estructura de M√≥dulos

```
src/cognitive_reader/
‚îú‚îÄ‚îÄ __init__.py                # API p√∫blica y exportaciones
‚îú‚îÄ‚îÄ _version.py                # Versionado autom√°tico
‚îú‚îÄ‚îÄ cli/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ main.py                # Interfaz de l√≠nea de comandos completa
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ progressive_reader.py  # Motor principal de lectura cognitiva
‚îÇ   ‚îî‚îÄ‚îÄ synthesizer.py         # S√≠ntesis jer√°rquica y generaci√≥n de conocimiento
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ client.py              # Cliente LLM abstracto con LangChain
‚îÇ   ‚îî‚îÄ‚îÄ prompts.py             # Gesti√≥n centralizada de prompts
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n con Pydantic v2
‚îÇ   ‚îú‚îÄ‚îÄ document.py            # Estructuras de documentos y secciones
‚îÇ   ‚îú‚îÄ‚îÄ knowledge.py           # Definiciones de conceptos y lenguajes
‚îÇ   ‚îî‚îÄ‚îÄ llm_responses.py       # Modelos de respuesta estructurada
‚îú‚îÄ‚îÄ parsers/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ docling_parser.py      # Parser universal con docling
‚îÇ   ‚îî‚îÄ‚îÄ structure_detector.py  # Detecci√≥n de estructura jer√°rquica
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ language.py            # Detecci√≥n de idioma
    ‚îú‚îÄ‚îÄ structure_formatter.py # Formateo y filtrado de estructura
    ‚îú‚îÄ‚îÄ text_cleaning.py       # Limpieza de texto
    ‚îî‚îÄ‚îÄ tokens.py              # Utilities para contexto y tokens
```

### Patr√≥n de Responsabilidades

#### **CognitiveReader** (Motor Principal)
- Orquestar el flujo completo de lectura cognitiva
- Gestionar procesamiento multi-pasada
- Coordinar entre componentes (parser, synthesizer, llm client)
- Aplicar filtros de desarrollo (max-depth, max-sections)

#### **DoclingParser** (Parsing Universal)
- Soporte multi-formato: PDF, DOCX, HTML, Markdown
- Conversi√≥n unificada a Markdown interno
- Extracci√≥n de metadatos de estructura jer√°rquica
- Configuraci√≥n optimizada para diferentes tipos de documento

#### **StructureDetector** (An√°lisis Jer√°rquico)
- Detecci√≥n autom√°tica de estructura jer√°rquica
- Construcci√≥n de relaciones padre-hijo
- Identificaci√≥n de secciones con/sin contenido propio
- Asignaci√≥n de √≠ndices de orden del documento

#### **LLMClient** (Abstracci√≥n LLM)
- Integraci√≥n con LangChain para m√∫ltiples proveedores
- Gesti√≥n de modelos duales (fast/main)
- Respuestas estructuradas con Pydantic
- Manejo de errores y reintentos
- Modos de desarrollo (dry-run, mock)

#### **Synthesizer** (Generaci√≥n de Conocimiento)
- S√≠ntesis jer√°rquica bottom-up
- Generaci√≥n de glosario de conceptos
- Filtrado inteligente de conceptos
- Construcci√≥n de metadata navegacional

#### **PromptManager** (Gesti√≥n de Prompts)
- Templates versionados y consistentes
- Soporte multi-idioma (EN/ES)
- Prompts optimizados por tipo de operaci√≥n
- Integraci√≥n del principio de autoridad

---

## üîÑ Algoritmo de Lectura Cognitiva

### Visi√≥n General del Procesamiento

```
[Documento] ‚Üí [Parsing] ‚Üí [Detecci√≥n Estructura] ‚Üí [Procesamiento Multi-pasada] ‚Üí [S√≠ntesis] ‚Üí [Conocimiento Cognitivo]
                                                           ‚Üì
                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                    ‚îÇ   PASADA 1:      ‚îÇ
                                                    ‚îÇ   Secuencial +   ‚îÇ
                                                    ‚îÇ   Contexto       ‚îÇ
                                                    ‚îÇ   Acumulativo    ‚îÇ
                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                           ‚Üì
                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                    ‚îÇ   PASADA 2:      ‚îÇ
                                                    ‚îÇ   Secuencial +   ‚îÇ
                                                    ‚îÇ   Contexto       ‚îÇ
                                                    ‚îÇ   Enriquecido    ‚îÇ
                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Algoritmo Secuencial Detallado

#### **Fase 1: Procesamiento Secuencial B√°sico**

1. **Ordenaci√≥n por Secuencia del Documento**
   ```python
   ordered_sections = sorted(sections, key=lambda s: s.order_index)
   ```

2. **Procesamiento Secuencial con Contexto Acumulativo**
   ```python
   for section in ordered_sections:
       # Construir contexto acumulativo
       cumulative_context = build_cumulative_context(section, summaries)
       
       if section.has_content and not section.children_ids:
           # Secci√≥n hoja: procesar directamente
           summary = process_section_with_authority(section, cumulative_context)
           summaries[section.id] = summary
           
           # Actualizar niveles superiores incrementalmente
           update_parent_levels_incrementally(section, summary, summaries)
           
       elif section.has_content and section.children_ids:
           # Padre con contenido: procesar contenido propio
           summary = process_section_with_authority(section, cumulative_context)
           summaries[section.id] = summary
           
       else:
           # Padre sin contenido: diferir hasta que todos los hijos est√©n procesados
           pending_parents[section.id] = section
   ```

3. **Construcci√≥n de Contexto Acumulativo**
   ```python
   def build_cumulative_context(section, summaries):
       context_parts = []
       
       # 1. Contextos de todos los niveles padre
       parent_contexts = get_parent_contexts(section, summaries)
       if parent_contexts:
           context_parts.append("PARENT CONTEXT:\n" + "\n\n".join(parent_contexts))
       
       # 2. Contextos de hermanos anteriores (mismo nivel, orden menor)
       sibling_contexts = get_previous_sibling_contexts(section, summaries)
       if sibling_contexts:
           context_parts.append("PREVIOUS SIBLINGS:\n" + "\n\n".join(sibling_contexts))
       
       return "\n\n".join(context_parts)
   ```

4. **Principio de Autoridad del Texto Fuente**
   ```python
   def process_section_with_authority(section, cumulative_context):
       authority_content = f"""CONTEXT (background information only):
{cumulative_context}

SOURCE TEXT (AUTHORITATIVE - supreme authority):
{section.content}

CRITICAL INSTRUCTIONS:
1. The SOURCE TEXT is your PRIMARY source of truth
2. Use CONTEXT only as background information to inform understanding
3. If SOURCE TEXT contradicts any CONTEXT information:
   - Trust the SOURCE TEXT completely
   - Update your understanding based on SOURCE TEXT
4. Generate summary that accurately reflects the SOURCE TEXT"""
       
       return process_with_llm(authority_content, language)
   ```

#### **Fase 2: Procesamiento Secuencial Enriquecido**

1. **Mismo Orden Secuencial**
   - Replica exactamente el mismo orden de la Pasada 1
   - Mantiene la consistencia del algoritmo secuencial

2. **Contexto Selectivo Enriquecido**
   ```python
   def build_enriched_cumulative_context(section, current_summaries, previous_summaries, concept_glossary):
       # Contexto base de pasada actual
       base_context = build_cumulative_context(section, current_summaries)
       
       enriched_parts = []
       if base_context:
           enriched_parts.append(f"CURRENT CONTEXT:\n{base_context}")
       
       # Resumen previo del mismo nodo (de Pasada 1)
       if section.id in previous_summaries:
           prev_summary = previous_summaries[section.id]
           enriched_parts.append(f"PREVIOUS SUMMARY OF THIS SECTION:\n{prev_summary.title}: {prev_summary.summary}")
       
       # Glosario de conceptos (limitado a 10 para contexto manejable)
       if concept_glossary:
           glossary_entries = [f"{concept}: {definition}" for concept, definition in list(concept_glossary.items())[:10]]
           enriched_parts.append("CONCEPT GLOSSARY:\n" + "\n".join(glossary_entries))
       
       return "\n\n".join(enriched_parts)
   ```

3. **Preservaci√≥n del Principio de Autoridad**
   ```python
   def process_section_with_enriched_authority(section, enriched_context):
       authority_content = f"""ENRICHED CONTEXT (background information only):
{enriched_context}

SOURCE TEXT (AUTHORITATIVE - supreme authority):
{section.content}

CRITICAL INSTRUCTIONS:
1. The SOURCE TEXT is your PRIMARY source of truth
2. Use ENRICHED CONTEXT only as background information
3. The enriched context includes previous summaries and concept definitions
4. If SOURCE TEXT contradicts any ENRICHED CONTEXT information:
   - Trust the SOURCE TEXT completely
5. Use concept definitions to enhance understanding but never override text meaning"""
       
       return process_with_llm(authority_content, language, model=main_model)
   ```

### Estrategia de Modelo Dual

#### **Configuraci√≥n de Modelos**

```python
class CognitiveConfig:
    # Modelo r√°pido para escaneo inicial (Pasada 1)
    fast_pass_model: str = "llama3.1:8b"
    fast_pass_temperature: float = 0.05  # Muy conservador para fidelidad
    
    # Modelo de calidad para procesamiento profundo (Pasada 2+)
    main_model: str = "qwen3:8b"
    main_pass_temperature: float = 0.05  # Muy conservador para fidelidad
    
    def get_model_for_pass(self, pass_number: int) -> str:
        if pass_number == 1 and self.enable_fast_first_pass:
            return self.fast_pass_model
        return self.main_model
```

#### **Beneficios de la Estrategia Dual**

- **Pasada 1 (R√°pida)**: Scan inicial eficiente para construir comprensi√≥n base
- **Pasada 2+ (Calidad)**: An√°lisis profundo con contexto enriquecido
- **Optimizaci√≥n de Costos**: Balance inteligente entre velocidad y calidad
- **Escalabilidad**: Procesa documentos grandes eficientemente

---

## üìä Estructuras de Datos

### Modelos Fundamentales

#### **DocumentSection** (Inmutable)
```python
@dataclass(frozen=True)
class DocumentSection:
    id: str                    # Identificador √∫nico
    title: str                 # T√≠tulo limpio de la secci√≥n
    content: str               # Contenido de texto completo
    level: int                 # Nivel jer√°rquico (0=root, 1=chapter, etc.)
    parent_id: Optional[str]   # ID de secci√≥n padre
    children_ids: List[str]    # IDs de secciones hijas
    order_index: int           # Orden de aparici√≥n en documento
    is_heading: bool = False   # True si representa encabezado real
```

#### **SectionSummary** (Resultado de Procesamiento)
```python
class SectionSummary(BaseModel):
    section_id: str           # Referencia a DocumentSection.id
    title: str                # T√≠tulo de secci√≥n
    summary: str              # Resumen cognitivo refinado
    key_concepts: List[str]   # Lista de conceptos clave (max 5)
    parent_id: Optional[str]  # ID de secci√≥n padre
    children_ids: List[str]   # IDs de secciones hijas
    level: int                # Nivel jer√°rquico
    order_index: int          # Orden de aparici√≥n
```

#### **ConceptDefinition** (Glosario Cognitivo)
```python
class ConceptDefinition(BaseModel):
    concept_id: str           # ID √∫nico (ej: "sedentarismo")
    name: str                 # Nombre legible
    definition: str           # Definici√≥n refinada cognitivamente
    first_mentioned_in: str   # ID de secci√≥n donde se identific√≥ primero
    relevant_sections: List[str]  # IDs donde el concepto es relevante
```

#### **CognitiveKnowledge** (Output Final)
```python
class CognitiveKnowledge(BaseModel):
    # Metadatos de documento
    document_title: str
    document_summary: str     # Resumen a nivel documento
    detected_language: LanguageCode
    
    # Res√∫menes jer√°rquicos (optimizados para RAG)
    hierarchical_summaries: Dict[str, SectionSummary]
    
    # Glosario de conceptos clave
    concepts: List[ConceptDefinition]
    
    # √çndices de navegaci√≥n
    hierarchy_index: Dict[str, List[str]]      # Nivel -> IDs de secci√≥n
    parent_child_map: Dict[str, List[str]]     # Padre -> Hijos
    
    # Estad√≠sticas
    total_sections: int
    avg_summary_length: float
    total_concepts: int
```

### Configuraci√≥n del Sistema

#### **CognitiveConfig** (Configuraci√≥n Completa)
```python
class CognitiveConfig(BaseModel):
    # Configuraci√≥n LLM
    model_name: str = "qwen3:8b"              # Modelo por defecto
    temperature: float = 0.1                  # Temperatura base
    
    # Estrategia de modelo dual
    enable_fast_first_pass: bool = True       # Usar modelo r√°pido para Pasada 1
    fast_pass_model: str = "llama3.1:8b"      # Modelo r√°pido
    main_model: str = "qwen3:8b"              # Modelo de calidad
    fast_pass_temperature: float = 0.05       # Temperatura para scan r√°pido
    main_pass_temperature: float = 0.05       # Temperatura para calidad
    
    # Configuraci√≥n multi-pasada
    num_passes: int = 2                       # N√∫mero de pasadas cognitivas
    max_passes: int = 2                       # M√°ximo pasadas (extensibilidad)
    convergence_threshold: float = 0.1        # Umbral de convergencia
    
    # Procesamiento de documentos
    chunk_size: int = 1000                    # Tama√±o de chunk
    chunk_overlap: int = 200                  # Solapamiento de chunks
    context_window: int = 16384               # Ventana de contexto LLM
    document_language: LanguageCode = AUTO    # Idioma del documento
    
    # Optimizaci√≥n de res√∫menes (basado en palabras para control natural)
    target_summary_words: int = 250           # Objetivo para res√∫menes de secci√≥n
    min_summary_words: int = 150              # M√≠nimo palabras
    max_summary_words: int = 400              # M√°ximo palabras
    target_document_summary_words: int = 400  # Objetivo para resumen de documento
    max_hierarchy_depth: int = 10             # Profundidad m√°xima de jerarqu√≠a
    
    # Caracter√≠sticas cognitivas
    enable_refinement: bool = True            # Habilitar refinamiento
    refinement_threshold: float = 0.4         # Umbral para refinamiento
    
    # Configuraci√≥n de proveedor LLM
    llm_provider: str = "ollama"              # Proveedor (ollama, openai, etc.)
    ollama_base_url: str = "http://localhost:11434"  # URL base de Ollama
    timeout_seconds: int = 120                # Timeout de requests
    max_retries: int = 3                      # M√°ximos reintentos
    
    # Filtrado de glosario
    max_glossary_concepts: int = 50           # M√°ximo conceptos en glosario
    min_glossary_concepts: int = 10           # M√≠nimo conceptos
    cross_section_score_cap: float = 0.5     # Cap para relevancia multi-secci√≥n
    complexity_score_multiplier: float = 0.2 # Multiplicador de complejidad
    complexity_score_cap: float = 0.3        # Cap de puntuaci√≥n de complejidad
    base_concept_score: float = 0.2           # Puntuaci√≥n base para conceptos LLM
    
    # Caracter√≠sticas de desarrollo
    dry_run: bool = False                     # Modo dry-run (sin llamadas LLM)
    mock_responses: bool = False              # Usar respuestas mock
    validate_config_only: bool = False        # Solo validar configuraci√≥n
    save_partial_results: bool = False        # Guardar resultados parciales
    partial_results_dir: str = "./partial_results"  # Directorio de parciales
    single_pass: bool = False                 # Forzar procesamiento de una pasada
    save_intermediate: bool = False           # Guardar estado entre pasadas
    intermediate_dir: str = "./intermediate_passes"  # Directorio intermedio
    max_sections: Optional[int] = None        # M√°ximo secciones (desarrollo)
    disable_reasoning: bool = False           # Desactivar modo reasoning
    skip_glossary: bool = False               # Saltar generaci√≥n de glosario
    show_context_usage: bool = False          # Mostrar uso de ventana de contexto
    
    @classmethod
    def from_env(cls) -> "CognitiveConfig":
        """Cargar configuraci√≥n desde variables de entorno con fallback a defaults."""
```

---

## üîß Stack Tecnol√≥gico y Dependencias

### Lenguaje y Runtime

#### **Python 3.12+**
- **Caracter√≠sticas modernas**: Type annotations, pattern matching, improved error messages
- **Async/await nativo**: Soporte completo para operaciones as√≠ncronas
- **Compatibilidad**: 3.12+ requerido para caracter√≠sticas de typing modernas

### Dependencias Principales

#### **Gesti√≥n de Datos y Validaci√≥n**
```toml
pydantic = ">=2.0,<3.0"      # Validaci√≥n de datos y configuraci√≥n
```
- Validaci√≥n autom√°tica de tipos
- Configuraci√≥n desde variables de entorno
- Serializaci√≥n JSON
- Modelos immutables con `frozen=True`

#### **Cliente HTTP As√≠ncrono**
```toml
aiohttp = ">=3.8,<4.0"       # Cliente HTTP async (backup para llamadas directas)
```
- Soporte para operaciones concurrentes
- Timeout y retry handling
- Context managers para gesti√≥n de recursos

#### **Framework CLI**
```toml
click = ">=8.0,<9.0"         # Framework para interfaz de l√≠nea de comandos
```
- Comandos complejos con m√∫ltiples opciones
- Validaci√≥n autom√°tica de par√°metros
- Help text generado autom√°ticamente
- Manejo de archivos y paths

#### **Procesamiento de Documentos**
```toml
docling = ">=2.40,<3.0"      # Parser universal de documentos
```
- Soporte para PDF, DOCX, HTML, Markdown
- Extracci√≥n de estructura jer√°rquica
- Configuraciones optimizadas por formato
- Conversi√≥n unificada a Markdown interno

#### **Detecci√≥n de Idioma**
```toml
langdetect = ">=1.0,<2.0"    # Detecci√≥n autom√°tica de idioma
```
- Auto-detecci√≥n de espa√±ol/ingl√©s
- Fallback configurable

#### **Configuraci√≥n de Entorno**
```toml
python-dotenv = ">=1.0,<2.0" # Soporte para archivos .env
```
- Carga autom√°tica de .env
- No sobrescribe variables existentes

#### **Integraci√≥n LLM**
```toml
langchain-core = ">=0.3,<1.0"    # Funcionalidad core de LangChain
langchain-ollama = ">=0.2,<1.0"  # Integraci√≥n con Ollama
```
- Abstracci√≥n de m√∫ltiples proveedores LLM
- Respuestas estructuradas con Pydantic
- Manejo de errores y reintentos integrado

### Herramientas de Desarrollo

#### **Testing**
```toml
pytest = ">=7.0,<8.0"           # Framework de testing
pytest-asyncio = ">=0.21,<1.0"  # Soporte async para pytest
```

#### **Linting y Formateo**
```toml
ruff = ">=0.1,<1.0"             # Linting y formateo ultra-r√°pido
```
- Configuraci√≥n:
  ```toml
  [tool.ruff]
  target-version = "py312"
  line-length = 88
  
  [tool.ruff.lint]
  select = ["E", "F", "I", "N", "W", "UP"]
  ignore = ["E501"]
  
  [tool.ruff.format]
  quote-style = "double"
  indent-style = "space"
  ```

#### **Verificaci√≥n de Tipos**
```toml
mypy = ">=1.0,<2.0"             # Verificaci√≥n est√°tica de tipos
```
- Configuraci√≥n estricta:
  ```toml
  [tool.mypy]
  python_version = "3.12"
  strict = true
  warn_return_any = true
  warn_unused_configs = true
  disallow_untyped_defs = true
  disallow_any_generics = true
  ```

### Gesti√≥n de Dependencias

#### **uv** (Herramienta Principal)
```bash
# Instalaci√≥n del proyecto
uv sync

# Comandos de desarrollo
uv run ruff check .
uv run ruff format .
uv run mypy src/
uv run pytest
uv run cognitive-reader --help
```

#### **Configuraci√≥n pyproject.toml**
```toml
[build-system]
requires = ["hatchling", "hatch-vcs"]
build-backend = "hatchling.build"

[project]
name = "cognitive-document-reader"
dynamic = ["version"]
requires-python = ">=3.12"

[project.scripts]
cognitive-reader = "cognitive_reader.cli.main:cli"

[tool.hatch.version]
source = "vcs"
tag-regex = "^v(?P<version>\\d+\\.\\d+\\.\\d+)$"

[tool.uv]
dev-dependencies = [
    "pytest>=7.0,<8.0",
    "pytest-asyncio>=0.21,<1.0",
    "ruff>=0.1,<1.0",
    "mypy>=1.0,<2.0",
]
```

---

## üåê Interfaz de Usuario

### API de Programaci√≥n

#### **Interfaz P√∫blica Principal**
```python
from cognitive_reader import CognitiveReader, CognitiveConfig

# Configuraci√≥n desde entorno
config = CognitiveConfig.from_env()

# Inicializaci√≥n
reader = CognitiveReader(config)

# Procesamiento de archivos
knowledge = await reader.read_document("document.pdf")

# Procesamiento de texto directo
knowledge = await reader.read_document_text(text_content, "Document Title")

# Acceso a resultados
print(knowledge.document_title)
print(knowledge.document_summary)
for section_id, summary in knowledge.hierarchical_summaries.items():
    print(f"{summary.title}: {summary.summary}")
```

#### **Configuraci√≥n Program√°tica**
```python
# Configuraci√≥n de desarrollo
config = CognitiveConfig(
    dry_run=True,
    mock_responses=True,
    save_partial_results=True,
    max_sections=5
)

# Configuraci√≥n de producci√≥n
config = CognitiveConfig(
    fast_pass_model="llama3.1:8b",
    main_model="qwen3:8b",
    num_passes=2,
    document_language=LanguageCode.ES
)

# Configuraci√≥n personalizada
config = CognitiveConfig(
    target_summary_words=300,
    max_glossary_concepts=30,
    context_window=32768
)
```

### Interfaz de L√≠nea de Comandos

#### **Comando Principal**
```bash
cognitive-reader [DOCUMENT] [OPTIONS]
```

#### **Opciones de Salida**
```bash
# Formatos de salida
--output, -o [json|markdown]        # Formato de output (default: markdown)
--output-file, -f PATH              # Guardar a archivo en lugar de stdout

# Configuraci√≥n de idioma
--language, -l [auto|en|es]         # Idioma del documento (default: auto)
```

#### **Configuraci√≥n de Modelo**
```bash
# Configuraci√≥n b√°sica
--model, -m MODEL                   # Modelo LLM a usar
--temperature, -t FLOAT             # Temperatura LLM (0.0-2.0)

# Modos de procesamiento
--fast-mode                         # Usar modelo r√°pido (optimiza velocidad)
--single-pass                       # Forzar procesamiento de una pasada
--disable-reasoning                 # Desactivar modo reasoning
```

#### **Caracter√≠sticas de Desarrollo**
```bash
# Modos de testing
--dry-run                          # Ejecutar sin llamadas LLM reales
--mock-responses                   # Usar respuestas mock para testing
--validate-config                  # Solo validar configuraci√≥n

# Control de procesamiento
--max-sections INT                 # M√°ximo secciones a procesar
--max-depth INT                    # M√°ximo nivel jer√°rquico
--structure-only                   # Mostrar solo estructura sin procesamiento

# Guardado de resultados
--save-partials                    # Guardar resultados parciales
--partials-dir PATH                # Directorio para resultados parciales
--save-intermediate                # Guardar estado entre pasadas

# Configuraci√≥n de res√∫menes
--target-words INT                 # Objetivo palabras para res√∫menes
--min-words INT                    # M√≠nimo palabras
--max-words INT                    # M√°ximo palabras
--skip-glossary                    # Saltar generaci√≥n de glosario

# Debugging y optimizaci√≥n
--show-context-usage               # Mostrar uso de ventana de contexto
--verbose, -v                      # Logging detallado
--quiet, -q                        # Suprimir output excepto resultados
```

#### **Ejemplos de Uso**
```bash
# Uso b√°sico
cognitive-reader document.pdf

# Desarrollo y testing
cognitive-reader document.md --dry-run --save-partials --max-sections 5

# Configuraci√≥n personalizada
cognitive-reader document.pdf --output json --language es --target-words 300

# An√°lisis r√°pido
cognitive-reader large_doc.pdf --fast-mode --max-depth 2 --skip-glossary

# Testing de estructura
cognitive-reader document.md --structure-only --max-depth 3
```

### Configuraci√≥n via Variables de Entorno

#### **Variables Principales**
```bash
# Configuraci√≥n LLM
COGNITIVE_READER_MODEL=qwen3:8b                    # Modelo por defecto
COGNITIVE_READER_TEMPERATURE=0.1                  # Temperatura base

# Estrategia dual
COGNITIVE_READER_FAST_PASS_MODEL=llama3.1:8b      # Modelo r√°pido
COGNITIVE_READER_MAIN_MODEL=qwen3:8b               # Modelo principal
COGNITIVE_READER_FAST_PASS_TEMPERATURE=0.05       # Temperatura scan r√°pido
COGNITIVE_READER_MAIN_PASS_TEMPERATURE=0.05       # Temperatura calidad

# Multi-pasada
COGNITIVE_READER_NUM_PASSES=2                     # N√∫mero de pasadas
COGNITIVE_READER_ENABLE_FAST_FIRST_PASS=true      # Habilitar dual model
COGNITIVE_READER_SINGLE_PASS=false                # Forzar single-pass
COGNITIVE_READER_SAVE_INTERMEDIATE=false          # Guardar intermedio

# Procesamiento
COGNITIVE_READER_CONTEXT_WINDOW=16384             # Ventana de contexto
COGNITIVE_READER_TARGET_SUMMARY_WORDS=250         # Palabras objetivo
COGNITIVE_READER_MAX_GLOSSARY_CONCEPTS=50         # Max conceptos glosario
COGNITIVE_READER_LANGUAGE=auto                    # Idioma (auto/en/es)

# Desarrollo
COGNITIVE_READER_DRY_RUN=false                    # Modo dry-run
COGNITIVE_READER_MOCK_RESPONSES=false             # Respuestas mock
COGNITIVE_READER_SAVE_PARTIAL_RESULTS=false      # Guardar parciales
COGNITIVE_READER_SHOW_CONTEXT_USAGE=false        # Mostrar uso contexto

# Proveedor LLM
COGNITIVE_READER_LLM_PROVIDER=ollama              # Proveedor
COGNITIVE_READER_OLLAMA_BASE_URL=http://localhost:11434  # URL Ollama
```

#### **Archivo .env de Ejemplo**
```bash
# Copia env.example a .env y modifica seg√∫n necesidades
cp env.example .env
```

---

## üìÑ Formatos de Entrada y Salida

### Formatos de Documento Soportados

#### **Formatos Principales** (con docling)
- **PDF** (.pdf): Preserva layout y estructura
- **DOCX** (.docx): Documentos Microsoft Word
- **HTML** (.html): P√°ginas web y contenido HTML
- **Markdown** (.md, .markdown): Soporte nativo optimizado

#### **Estrategia de Procesamiento**
- Docling integrado para todos los formatos soportados
- Conversi√≥n interna unificada a Markdown para procesamiento consistente
- Detecci√≥n autom√°tica de formato basada en extensi√≥n
- Configuraciones optimizadas por tipo de documento

### Formato de Salida JSON

#### **Estructura Completa**
```json
{
  "document_title": "T√≠tulo del Documento",
  "document_summary": "Resumen cognitivo a nivel documento...",
  "detected_language": "es",
  
  "hierarchical_summaries": {
    "section_1": {
      "section_id": "section_1",
      "title": "Introducci√≥n",
      "summary": "Resumen cognitivo refinado de la secci√≥n...",
      "key_concepts": ["concepto1", "concepto2", "concepto3"],
      "parent_id": null,
      "children_ids": ["section_1_1", "section_1_2"],
      "level": 1,
      "order_index": 0
    },
    "section_1_1": {
      "section_id": "section_1_1",
      "title": "Antecedentes",
      "summary": "Contexto hist√≥rico y marco te√≥rico...",
      "key_concepts": ["concepto_historico", "marco_teorico"],
      "parent_id": "section_1",
      "children_ids": [],
      "level": 2,
      "order_index": 1
    }
  },
  
  "concepts": [
    {
      "concept_id": "concepto1",
      "name": "Concepto Principal",
      "definition": "Definici√≥n cognitiva refinada con contexto espec√≠fico del documento...",
      "first_mentioned_in": "section_1",
      "relevant_sections": ["section_1", "section_2", "section_3"]
    }
  ],
  
  "hierarchy_index": {
    "0": ["root"],
    "1": ["section_1", "section_2", "section_3"],
    "2": ["section_1_1", "section_1_2", "section_2_1"]
  },
  
  "parent_child_map": {
    "root": ["section_1", "section_2", "section_3"],
    "section_1": ["section_1_1", "section_1_2"]
  },
  
  "total_sections": 8,
  "avg_summary_length": 247.5,
  "total_concepts": 12
}
```

### Formato de Salida Markdown

#### **Estructura Markdown**
```markdown
# T√≠tulo del Documento - An√°lisis Cognitivo

> **Procesamiento**: Lectura cognitiva de 2 pasadas | 8 secciones | 12 conceptos

## üìñ Resumen del Documento
Resumen cognitivo completo que integra comprensi√≥n de todas las secciones...

## üìÑ Res√∫menes de Secciones

### 1. Introducci√≥n
**Resumen**: Resumen cognitivo refinado de la secci√≥n...
**Conceptos Clave**: concepto1, concepto2, concepto3

#### 1.1. Antecedentes
**Resumen**: Contexto hist√≥rico y marco te√≥rico...
**Conceptos Clave**: concepto_historico, marco_teorico

## üìö Glosario de Conceptos

### concepto1 - Concepto Principal
Definici√≥n cognitiva refinada con contexto espec√≠fico del documento...
*Primera menci√≥n*: Introducci√≥n
*Relevante en*: Introducci√≥n, Desarrollo, Conclusiones

## üìä Estad√≠sticas de Procesamiento
- **Total de secciones**: 8
- **Promedio longitud res√∫menes**: 247.5 caracteres
- **Total conceptos identificados**: 12
```

### Formatos de Desarrollo

#### **Resultados Parciales** (JSON)
```json
{
  "progress": {
    "section_index": 3,
    "total_sections": 8,
    "progress_percentage": 37.5
  },
  "section": {
    "id": "section_3",
    "title": "Metodolog√≠a",
    "level": 1,
    "order_index": 2,
    "content_preview": "La metodolog√≠a empleada en este estudio..."
  },
  "summary": {
    "title": "Metodolog√≠a",
    "summary": "Descripci√≥n detallada del enfoque metodol√≥gico...",
    "key_concepts": ["metodologia", "enfoque_cuantitativo", "analisis_estadistico"],
    "level": 1,
    "order_index": 2
  },
  "context": {
    "accumulated_context_length": 1247,
    "accumulated_context_preview": "Introducci√≥n: Contexto general del problema..."
  },
  "config": {
    "model_used": "llama3.1:8b",
    "enable_fast_first_pass": true,
    "temperature": 0.05
  }
}
```

#### **Resultados Intermedios** (JSON)
```json
{
  "pass_number": 1,
  "description": "Sequential processing with cumulative context",
  "language": "es",
  "timestamp": "20241215_143052",
  "total_sections": 8,
  "total_summaries": 8,
  "sections": [...],
  "summaries": {...}
}
```

---

## üîç Gesti√≥n de Prompts

### Arquitectura de Prompts

#### **PromptManager** (Centralizado)
```python
class PromptManager:
    PROMPT_VERSION = "v1.4.0"  # Versionado de prompts
    
    LANGUAGE_NAMES = {
        LanguageCode.EN: "English",
        LanguageCode.ES: "Spanish",
        LanguageCode.AUTO: "English"
    }
    
    def get_prompt(self, prompt_type: str, language: LanguageCode) -> str:
        # Template unificado con reemplazo de {{language}}
        
    def format_section_summary_prompt(
        self, section_title: str, section_content: str, 
        accumulated_context: str, language: LanguageCode,
        target_words: int, min_words: int, max_words: int
    ) -> str:
        # Prompt para res√∫menes de secci√≥n con par√°metros de longitud
```

#### **Templates de Prompts Principales**

**1. Resumen de Secci√≥n**
```
You are an expert document analyzer specializing in creating high-quality summaries in {{language}}.

CONTEXT FROM PREVIOUS SECTIONS:
{accumulated_context}

SECTION TO ANALYZE:
Title: {section_title}
Content: {section_content}

INSTRUCTIONS:
Create a comprehensive summary in {{language}} that:
1. Captures the main ideas and key points
2. Maintains context from previous sections
3. Identifies important concepts and terminology
4. Length: {target_words} words (min: {min_words}, max: {max_words})

Provide:
1. A clear, informative summary
2. Up to 5 key concepts found in this section
```

**2. Resumen de Documento**
```
You are an expert document analyzer creating a comprehensive document summary in {{language}}.

DOCUMENT TITLE: {document_title}

SECTION SUMMARIES:
{section_summaries}

INSTRUCTIONS:
Create a comprehensive document-level summary in {{language}} that:
1. Integrates insights from all sections
2. Captures the document's main thesis and conclusions
3. Maintains coherence and logical flow
4. Length: {target_words} words (min: {min_words}, max: {max_words})

Focus on the document's primary contributions and key insights.
```

**3. Definici√≥n de Conceptos**
```
You are an expert in {{language}} specialized in creating precise concept definitions.

DOCUMENT CONTEXT:
{document_summary}

CONCEPT TO DEFINE: {concept_name}

SECTIONS WHERE MENTIONED:
{relevant_sections}

INSTRUCTIONS:
Create a precise definition in {{language}} for this concept that:
1. Is accurate based on how it's used in this document
2. Captures the specific meaning in this context
3. Is clear and informative
4. Avoids generic definitions - focus on document-specific usage

Provide only the definition, no meta-commentary.
```

### Principio de Autoridad en Prompts

#### **Template de Autoridad para Contexto**
```
CONTEXT (background information only):
{cumulative_context}

SOURCE TEXT (AUTHORITATIVE - supreme authority):
{section_content}

CRITICAL INSTRUCTIONS:
1. The SOURCE TEXT is your PRIMARY source of truth
2. Use CONTEXT only as background information to inform understanding
3. If SOURCE TEXT contradicts any CONTEXT information:
   - Trust the SOURCE TEXT completely
   - Update your understanding based on SOURCE TEXT
   - The SOURCE TEXT is always correct
4. Generate summary that accurately reflects the SOURCE TEXT
5. Identify concepts mentioned in SOURCE TEXT (not just from context)

Remember: SOURCE TEXT has supreme authority over all context information.
```

#### **Template de Autoridad para Contexto Enriquecido**
```
ENRICHED CONTEXT (background information only):
{enriched_context}

SOURCE TEXT (AUTHORITATIVE - supreme authority):
{section_content}

CRITICAL INSTRUCTIONS:
1. The SOURCE TEXT is your PRIMARY source of truth
2. Use ENRICHED CONTEXT only as background information
3. The enriched context includes previous summaries and concept definitions
4. If SOURCE TEXT contradicts any ENRICHED CONTEXT information:
   - Trust the SOURCE TEXT completely
   - Update your understanding based on SOURCE TEXT
5. Generate summary that accurately reflects the SOURCE TEXT
6. Use concept definitions to enhance understanding but never override text meaning

Remember: SOURCE TEXT has supreme authority over all enriched context information.
```

### Respuestas Estructuradas

#### **Modelos de Respuesta LLM**
```python
class SectionSummaryResponse(BaseModel):
    summary: str = Field(description="Clear, concise summary of the section content")
    key_concepts: List[str] = Field(
        max_length=5,
        description="List of up to 5 key concepts found in the section"
    )

class ConceptDefinitionResponse(BaseModel):
    definition: str = Field(
        description="Clear, direct definition of the concept without meta-references"
    )
```

---

## ‚öôÔ∏è Requisitos No Funcionales

### Rendimiento

#### **Requisitos de Velocidad**
- **Tiempo de procesamiento**: <2 minutos para documentos de 50 p√°ginas en modo dual
- **Tiempo de scan inicial**: <30 segundos para documentos de 50 p√°ginas en modo r√°pido
- **Paralelizaci√≥n**: Soporte para procesamiento concurrente de m√∫ltiples documentos
- **Memoria**: <500MB de RAM para documentos t√≠picos (<100 p√°ginas)

#### **Optimizaciones**
- **Modelo dual**: Balance autom√°tico entre velocidad (fast model) y calidad (main model)
- **Contexto inteligente**: Truncado autom√°tico de contexto cuando excede l√≠mites
- **Caching**: Reutilizaci√≥n de contexto entre pasadas
- **Batching**: Agrupaci√≥n eficiente de requests LLM cuando sea posible

### Escalabilidad

#### **L√≠mites de Documento**
- **Tama√±o m√°ximo**: 500 p√°ginas (configurable)
- **Secciones m√°ximas**: 1000 secciones (configurable via `max_sections`)
- **Profundidad jer√°rquica**: 10 niveles (configurable via `max_hierarchy_depth`)
- **Conceptos en glosario**: 50 conceptos (configurable via `max_glossary_concepts`)

#### **Gesti√≥n de Recursos**
- **Ventana de contexto**: Manejo din√°mico seg√∫n modelo LLM (default 16384 tokens)
- **L√≠mites de memoria**: Procesamiento streaming para documentos grandes
- **Timeout inteligente**: Incremento autom√°tico de timeout para documentos complejos
- **Fallback graceful**: Degradaci√≥n elegante ante errores de recursos

### Confiabilidad

#### **Manejo de Errores**
- **Reintentos autom√°ticos**: Hasta 3 reintentos con backoff exponencial
- **Fallback de modelos**: Cambio autom√°tico a modelo alternativo ante fallos
- **Validaci√≥n de entrada**: Validaci√≥n exhaustiva de documentos antes del procesamiento
- **Recuperaci√≥n parcial**: Continuaci√≥n desde √∫ltimo estado v√°lido en caso de fallo

#### **Tolerancia a Fallos**
- **Guardar estado intermedio**: Checkpoints autom√°ticos entre pasadas
- **Validaci√≥n de salida**: Verificaci√≥n de integridad de resultados
- **Logs detallados**: Trazabilidad completa de errores para debugging
- **Modo degradado**: Funcionamiento con funcionalidades reducidas ante fallos parciales

### Mantenibilidad

#### **Versionado y Evoluci√≥n**
- **API estable**: Compatibilidad hacia atr√°s de interfaces principales
- **Schema versionado**: JSON output con versioning para consumidores
- **Prompts versionados**: Control de versi√≥n de templates con n√∫meros de versi√≥n
- **Configuraci√≥n extensible**: Adici√≥n de nuevos par√°metros sin romper compatibilidad

#### **Debugging y Monitoreo**
- **Modos de desarrollo**: dry-run, mock responses, partial saves
- **Logs estructurados**: Informaci√≥n detallada para troubleshooting
- **M√©tricas de rendimiento**: Tracking de tiempo, memoria, y uso de contexto
- **Validaci√≥n de configuraci√≥n**: Verificaci√≥n completa de setup antes de procesamiento

### Seguridad

#### **Protecci√≥n de Datos**
- **Procesamiento local**: LLMs locales por defecto (Ollama)
- **Sin persistencia**: Datos no almacenados permanentemente salvo configuraci√≥n expl√≠cita
- **Sanitizaci√≥n de entrada**: Limpieza de contenido potencialmente problem√°tico
- **Aislamiento de procesos**: Separaci√≥n entre procesamiento y almacenamiento

#### **Configuraci√≥n Segura**
- **Variables de entorno**: Configuraci√≥n sensible via environment variables
- **Validaci√≥n estricta**: Pydantic validation para todos los inputs
- **URLs configurables**: No hardcoding de endpoints
- **Timeouts apropiados**: Protecci√≥n contra hanging requests

### Usabilidad

#### **Experiencia de Desarrollo**
- **Documentaci√≥n completa**: Ejemplos, gu√≠as, y API reference
- **Mensajes de error claros**: Informaci√≥n espec√≠fica y accionable
- **Configuraci√≥n flexible**: Multiple m√©todos de configuraci√≥n
- **Testing integrado**: Modos mock para desarrollo sin dependencias

#### **Experiencia de Usuario Final**
- **CLI intuitiva**: Comandos claros con help integrado
- **Feedback de progreso**: Indicadores de avance para documentos largos
- **M√∫ltiples formatos**: Salida en JSON y Markdown seg√∫n necesidades
- **Validaci√≥n temprana**: Detecci√≥n de problemas antes del procesamiento completo

---

## üß™ Estrategia de Testing

### Arquitectura de Testing

#### **Organizaci√≥n de Tests**
```
tests/
‚îú‚îÄ‚îÄ conftest.py                    # Fixtures compartidas
‚îú‚îÄ‚îÄ fixtures/                     # Datos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ sample_documents/
‚îÇ   ‚îú‚îÄ‚îÄ expected_outputs/
‚îÇ   ‚îî‚îÄ‚îÄ mock_responses/
‚îú‚îÄ‚îÄ unit/                         # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ test_cognitive_models.py  # Models y validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_cli.py              # Interfaz CLI
‚îÇ   ‚îú‚îÄ‚îÄ test_concept_filtering.py # Filtrado de conceptos
‚îÇ   ‚îú‚îÄ‚îÄ test_language_detection.py # Detecci√≥n de idioma
‚îÇ   ‚îú‚îÄ‚îÄ test_structure_formatter.py # Formateo de estructura
‚îÇ   ‚îî‚îÄ‚îÄ test_text_cleaning.py     # Utilidades de texto
‚îî‚îÄ‚îÄ integration/                  # Tests de integraci√≥n
    ‚îú‚îÄ‚îÄ test_fast_first_pass.py   # Testing de modelo dual
    ‚îú‚îÄ‚îÄ test_multi_pass_features.py # Testing multi-pasada
    ‚îî‚îÄ‚îÄ test_end_to_end.py         # Flujo completo
```

### Tipos de Tests

#### **Tests Unitarios**
```python
# test_cognitive_models.py
def test_cognitive_config_from_env():
    """Test configuration loading from environment variables."""
    
def test_document_section_immutability():
    """Test that DocumentSection is properly frozen."""
    
def test_concept_definition_validation():
    """Test ConceptDefinition validation rules."""

# test_structure_detector.py  
def test_hierarchy_detection():
    """Test detection of hierarchical document structure."""
    
def test_parent_child_relationships():
    """Test correct parent-child relationship building."""

# test_text_cleaning.py
def test_section_title_cleaning():
    """Test section title cleaning and normalization."""
```

#### **Tests de Integraci√≥n**
```python
# test_multi_pass_features.py
@pytest.mark.asyncio
async def test_dual_pass_processing():
    """Test complete dual-pass processing workflow."""
    
@pytest.mark.asyncio 
async def test_enriched_context_integration():
    """Test that second pass uses enriched context correctly."""

# test_fast_first_pass.py
@pytest.mark.asyncio
async def test_model_selection_per_pass():
    """Test that correct models are used for each pass."""
```

#### **Tests End-to-End**
```python
# test_end_to_end.py
@pytest.mark.asyncio
async def test_complete_document_processing():
    """Test complete processing from file to CognitiveKnowledge."""
    
@pytest.mark.asyncio
async def test_authority_principle_preservation():
    """Test that text authority principle is maintained throughout."""
```

### Estrategias de Mocking

#### **Mock de LLM Responses**
```python
# conftest.py
@pytest.fixture
def mock_llm_responses():
    return {
        "section_summary": SectionSummaryResponse(
            summary="Mock section summary",
            key_concepts=["concept1", "concept2"]
        ),
        "concept_definition": ConceptDefinitionResponse(
            definition="Mock concept definition"
        )
    }

@pytest.fixture
def mock_llm_client(mock_llm_responses):
    """Mock LLM client that returns predefined responses."""
    with patch('cognitive_reader.llm.client.LLMClient') as mock:
        mock_instance = mock.return_value.__aenter__.return_value
        mock_instance.generate_structured_summary.return_value = mock_llm_responses["section_summary"]
        yield mock_instance
```

#### **Mock de Document Parser**
```python
@pytest.fixture
def mock_docling_parser():
    """Mock docling parser with sample document structure."""
    with patch('cognitive_reader.parsers.docling_parser.DoclingParser') as mock:
        mock_instance = mock.return_value
        mock_instance.parse_document.return_value = (
            "Sample Document",
            [
                DocumentSection(
                    id="section_1",
                    title="Introduction", 
                    content="This is the introduction content.",
                    level=1,
                    order_index=0
                )
            ]
        )
        yield mock_instance
```

### Fixtures de Testing

#### **Documentos de Prueba**
```python
# conftest.py
@pytest.fixture
def sample_markdown_document():
    """
    Fictional sample document designed for cognitive reading evaluation.
    
    Note: 'Aethelgard's Crystalline Consciousness Theory' is completely fictional,
    created specifically to test:
    - Novel semantic content processing (not in LLM training data)
    - Concept redefinition handling (e.g., empathy redefined as physical resonance)
    - Structural hierarchy processing (parents with/without content)
    - Title cleaning and normalization
    """
    return """# Aethelgard's Crystalline Consciousness Theory

## Fundamental Principles
The crystalline consciousness theory, proposed by xenophysicist Elara Aethelgard...

### Background
Historical context and previous work.

## Methodology  
Description of approach used.

## Results
Key findings and analysis.

## Conclusion
Summary and implications."""

@pytest.fixture  
def sample_document_sections():
    """Sample DocumentSection objects for testing."""
    return [
        DocumentSection(
            id="root",
            title="Aethelgard's Crystalline Consciousness Theory",
            content="# Aethelgard's Crystalline Consciousness Theory",
            level=0,
            order_index=0
        ),
        DocumentSection(
            id="principles",
            title="Fundamental Principles", 
            content="The crystalline consciousness theory, proposed by xenophysicist Elara Aethelgard...",
            level=1,
            parent_id="root",
            order_index=1
        )
        # ... m√°s secciones
    ]
```

#### **Configuraciones de Testing**
```python
@pytest.fixture
def test_config():
    """Basic test configuration with development features."""
    return CognitiveConfig(
        dry_run=True,
        mock_responses=True,
        save_partial_results=False,
        max_sections=5,
        target_summary_words=100,
        max_glossary_concepts=10
    )

@pytest.fixture
def production_config():
    """Production-like configuration for integration tests."""
    return CognitiveConfig(
        fast_pass_model="llama3.1:8b",
        main_model="qwen3:8b", 
        num_passes=2,
        dry_run=False,  # Para tests de integraci√≥n real
        target_summary_words=250
    )
```

### M√©tricas de Calidad

#### **Cobertura de C√≥digo**
- **Objetivo**: 90% cobertura m√≠nima
- **Herramienta**: pytest-cov
- **Comando**: `pytest --cov=cognitive_reader --cov-report=html`

#### **Testing de Caracter√≠sticas Cr√≠ticas**
- **Principio de autoridad**: Verificar que texto fuente prevalece sobre contexto
- **Contexto acumulativo**: Validar construcci√≥n correcta de contexto
- **Algoritmo secuencial**: Confirmar orden correcto de procesamiento
- **Modelo dual**: Verificar selecci√≥n correcta de modelo por pasada

#### **Testing de Casos Edge**
- **Documentos vac√≠os**: Manejo de documentos sin contenido
- **Estructura malformada**: Documentos con jerarqu√≠a inconsistente
- **Contenido muy largo**: Documentos que excedan l√≠mites de contexto
- **Errores de LLM**: Fallos y timeouts de modelos LLM

#### **Performance Testing**
```python
@pytest.mark.performance
def test_processing_time_limits():
    """Test that processing completes within acceptable time limits."""
    
@pytest.mark.performance
def test_memory_usage_bounds():
    """Test that memory usage stays within expected bounds."""
```

---

## üìã Checklist de Implementaci√≥n

### Fase 1: Fundamentos y Configuraci√≥n

#### **Setup de Proyecto**
- [ ] Configurar estructura de proyecto con src/ layout
- [ ] Configurar pyproject.toml con dependencias correctas
- [ ] Implementar _version.py con versionado autom√°tico
- [ ] Configurar herramientas de desarrollo (ruff, mypy, pytest)
- [ ] Implementar gesti√≥n de .env con python-dotenv

#### **Modelos de Datos**
- [ ] Implementar LanguageCode enum
- [ ] Crear DocumentSection como dataclass inmutable
- [ ] Implementar SectionSummary con Pydantic
- [ ] Crear ConceptDefinition para glosario
- [ ] Implementar CognitiveKnowledge como output final
- [ ] Implementar CognitiveConfig con from_env()

#### **Sistema de Configuraci√≥n**
- [ ] Mapeo completo de variables de entorno
- [ ] Validaci√≥n con Pydantic v2
- [ ] M√©todos auxiliares (get_model_for_pass, get_temperature_for_pass)
- [ ] Soporte para .env file loading

### Fase 2: Parsing y Estructura

#### **Parser Universal**
- [ ] Implementar DoclingParser para todos los formatos
- [ ] Soporte para PDF, DOCX, HTML, Markdown
- [ ] Detecci√≥n autom√°tica de formato por extensi√≥n
- [ ] Integraci√≥n con StructureDetector

#### **Detecci√≥n de Estructura**
- [ ] Algoritmo de detecci√≥n de jerarqu√≠a
- [ ] Construcci√≥n de relaciones padre-hijo
- [ ] Asignaci√≥n de order_index secuencial
- [ ] Identificaci√≥n de secciones con/sin contenido

#### **Utilidades de Texto**
- [ ] Implementar text_cleaning.py
- [ ] Implementar structure_formatter.py
- [ ] Implementar language.py con langdetect
- [ ] Implementar tokens.py para gesti√≥n de contexto

### Fase 3: Cliente LLM y Prompts

#### **Cliente LLM Abstracto**
- [ ] Integraci√≥n con LangChain
- [ ] Soporte para modelos Ollama
- [ ] Respuestas estructuradas con Pydantic
- [ ] Manejo de errores y reintentos
- [ ] Context manager para gesti√≥n de recursos

#### **Gesti√≥n de Prompts**
- [ ] Implementar PromptManager con versionado
- [ ] Templates para res√∫menes de secci√≥n
- [ ] Templates para res√∫menes de documento
- [ ] Templates para definiciones de conceptos
- [ ] Prompts con principio de autoridad
- [ ] Soporte multi-idioma (EN/ES)

#### **Modos de Desarrollo**
- [ ] Implementar dry-run mode
- [ ] Implementar mock responses
- [ ] Implementar show_context_usage
- [ ] Validaci√≥n de configuraci√≥n

### Fase 4: Motor de Lectura Cognitiva

#### **Algoritmo Secuencial**
- [ ] Implementar _order_by_document_sequence()
- [ ] Implementar _build_cumulative_context()
- [ ] Implementar _get_parent_contexts()
- [ ] Implementar _get_previous_sibling_contexts()
- [ ] Implementar _process_section_with_authority()

#### **Procesamiento Multi-pasada**
- [ ] Implementar _multi_pass_processing()
- [ ] Implementar _sequential_processing_with_enriched_context()
- [ ] Implementar _build_enriched_cumulative_context()
- [ ] Implementar _process_section_with_enriched_authority()
- [ ] Implementar _save_intermediate_pass()

#### **Manejo de Secciones Especiales**
- [ ] Implementar _update_parent_levels_incrementally()
- [ ] Implementar _process_pending_parents()
- [ ] Implementar _synthesize_parent_from_children()
- [ ] Implementar _finalize_pending_parents()

#### **Caracter√≠sticas de Desarrollo**
- [ ] Implementar _apply_section_filters()
- [ ] Implementar _filter_by_depth()
- [ ] Implementar _save_partial_result()
- [ ] Implementar filtros max_sections

### Fase 5: Synthesizer y Generaci√≥n de Conocimiento

#### **S√≠ntesis Jer√°rquica**
- [ ] Implementar synthesize_document()
- [ ] Implementar _generate_document_summary()
- [ ] Implementar _synthesize_container_sections()

#### **Generaci√≥n de Glosario**
- [ ] Implementar _generate_concept_definitions()
- [ ] Implementar _filter_concepts_for_glossary()
- [ ] Implementar scoring algoritm para conceptos
- [ ] Soporte para skip_glossary

#### **Output Final**
- [ ] Construcci√≥n de CognitiveKnowledge
- [ ] Generaci√≥n de hierarchy_index
- [ ] Generaci√≥n de parent_child_map
- [ ] C√°lculo de estad√≠sticas

### Fase 6: CLI y Interfaces

#### **Comando Principal**
- [ ] Implementar cli() con click
- [ ] Manejo de argumentos y opciones completas
- [ ] Validaci√≥n de entrada y paths
- [ ] Manejo de errores user-friendly

#### **Modos de Operaci√≥n**
- [ ] Implementar --structure-only
- [ ] Implementar --validate-config
- [ ] Implementar --fast-mode
- [ ] Implementar todas las opciones de desarrollo

#### **Formatos de Salida**
- [ ] Implementar output JSON completo
- [ ] Implementar output Markdown con formato
- [ ] Implementar --output-file
- [ ] Soporte para --verbose y --quiet

### Fase 7: Testing y Calidad

#### **Setup de Testing**
- [ ] Configurar pytest con asyncio
- [ ] Implementar conftest.py con fixtures
- [ ] Crear documentos de prueba
- [ ] Configurar pytest.ini_options

#### **Tests Unitarios**
- [ ] Tests de modelos de datos
- [ ] Tests de configuraci√≥n
- [ ] Tests de utilidades
- [ ] Tests de parsers
- [ ] Tests de prompts

#### **Tests de Integraci√≥n**
- [ ] Tests de flujo completo
- [ ] Tests de modelo dual
- [ ] Tests de multi-pasada
- [ ] Tests de principio de autoridad

#### **Mocking y Fixtures**
- [ ] Mock de LLM responses
- [ ] Mock de docling parser
- [ ] Fixtures de configuraci√≥n
- [ ] Fixtures de documentos de prueba

### Fase 8: Documentaci√≥n y Packaging

#### **Documentaci√≥n**
- [ ] README.md completo con ejemplos
- [ ] Documentaci√≥n de API
- [ ] Gu√≠as de configuraci√≥n
- [ ] Ejemplos de uso

#### **Packaging**
- [ ] Configuraci√≥n de build con hatchling
- [ ] Entry points para CLI
- [ ] Versionado autom√°tico con hatch-vcs
- [ ] Configuraci√≥n de distribuci√≥n

#### **Scripts y Herramientas**
- [ ] Scripts de desarrollo
- [ ] Configuraci√≥n de CI/CD
- [ ] Herramientas de an√°lisis de c√≥digo

---

## üéØ Consideraciones de Implementaci√≥n

### Principios de Dise√±o T√©cnico

#### **Principio de Autoridad del Texto Fuente**
- **CR√çTICO**: Implementar en todos los prompts la jerarqu√≠a: Texto Original > Contexto Actual > Contexto Previo
- **Validaci√≥n**: Tests espec√≠ficos que verifiquen que el texto fuente prevalece sobre informaci√≥n contextual conflictiva
- **Prompts**: Estructurar todos los prompts con instrucciones expl√≠citas sobre autoridad

#### **Algoritmo Secuencial Aut√©ntico**
- **CR√çTICO**: Procesar secciones en order_index (orden del documento), NO por nivel jer√°rquico
- **Contexto Acumulativo**: Construir contexto de padres + hermanos previos para cada secci√≥n
- **Actualizaciones Incrementales**: Los niveles superiores evolucionan conforme se procesan hijos

#### **Inmutabilidad de Estructuras B√°sicas**
- **DocumentSection**: Frozen dataclass para prevenir modificaciones accidentales
- **Configuraci√≥n**: Pydantic models para validaci√≥n autom√°tica
- **Thread Safety**: Estructuras inmutables facilitan procesamiento concurrente

### Optimizaciones de Rendimiento

#### **Gesti√≥n de Memoria**
- **Streaming**: Procesar documentos grandes por secciones sin cargar todo en memoria
- **Context Truncation**: Truncado inteligente de contexto cuando excede l√≠mites del modelo
- **Garbage Collection**: Liberar referencias a secciones procesadas cuando sea posible

#### **Paralelizaci√≥n**
- **Concurrent Processing**: Posibilidad de procesar m√∫ltiples documentos concurrentemente
- **Async I/O**: Todas las operaciones LLM deben ser as√≠ncronas
- **Batching**: Agrupar requests LLM similares cuando sea posible

#### **Caching Inteligente**
- **Context Reuse**: Reutilizar contexto construido entre pasadas cuando sea apropiado
- **Model Warming**: Mantener modelos LLM "warm" para requests subsecuentes
- **Response Caching**: Cache opcional para respuestas LLM id√©nticas (desarrollo)

### Manejo de Errores y Robustez

#### **Estrategia de Fallback**
- **Model Fallback**: Si fast_model falla, usar main_model como backup
- **Format Fallback**: Si un formato espec√≠fico falla, intentar procesamiento como texto plano
- **Partial Processing**: Continuar procesamiento a√∫n con secciones que fallan

#### **Recuperaci√≥n de Estado**
- **Checkpointing**: Guardar estado entre pasadas para recuperaci√≥n
- **Incremental Processing**: Posibilidad de continuar desde √∫ltima secci√≥n exitosa
- **Error Context**: Logging detallado de contexto cuando ocurren errores

#### **Validaci√≥n Exhaustiva**
- **Input Validation**: Validar documentos antes del procesamiento
- **Output Validation**: Verificar integridad de CognitiveKnowledge antes de retornar
- **Configuration Validation**: Verificaci√≥n temprana de configuraci√≥n

### Extensibilidad y Evoluci√≥n

#### **Arquitectura Pluggable**
- **LLM Providers**: Interfaz abstracta para a√±adir nuevos proveedores (OpenAI, Anthropic)
- **Document Parsers**: Sistema de plugins para nuevos formatos
- **Prompt Templates**: Sistema de templates extensible con versionado

#### **Backward Compatibility**
- **API Versioning**: Mantener compatibilidad de API p√∫blica
- **Configuration Migration**: Migraci√≥n autom√°tica de configuraciones obsoletas
- **Schema Evolution**: Versionado de JSON output schema

#### **Multi-pass Extension**
- **N-pass Architecture**: Dise√±o preparado para m√°s de 2 pasadas
- **Convergence Detection**: Detectar cu√°ndo pasadas adicionales no aportan valor
- **Specialized Passes**: Framework para pasadas especializadas (fact-checking, etc.)

---

*Este documento de especificaciones t√©cnicas v3.0 representa una ingenier√≠a inversa completa del proyecto Cognitive Document Reader implementado, proporcionando todas las especificaciones t√©cnicas necesarias para reimplementar el proyecto desde cero con la misma funcionalidad y arquitectura.*
