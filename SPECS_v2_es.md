# Cognitive Document Reader - Especificaciones T√©cnicas v2.0

> **Versi√≥n 2.0**: Redise√±o arquitect√≥nico basado en el proceso aut√©ntico de lectura cognitiva humana detallado en `MOTIVATION_es.md`

---

## üìö Contexto: ¬øPor Qu√© la Versi√≥n 2.0?

**La Versi√≥n 2.0** representa un cambio arquitect√≥nico fundamental del enfoque de procesamiento secuencial original (v1.x) para implementar el aut√©ntico **proceso de lectura cognitiva de dos pasadas** descrito en detalle en [`MOTIVATION_es.md`](./MOTIVATION_es.md).

### **El Problema con la v1.x**
La especificaci√≥n original (preservada en el git tag `v0.1.1`) implementaba solo:
- ‚úÖ Lectura progresiva secuencial  
- ‚úÖ S√≠ntesis jer√°rquica b√°sica
- ‚ùå **Faltaba**: Refinamiento continuo durante la lectura
- ‚ùå **Faltaba**: Enriquecimiento contextual de segunda pasada  
- ‚ùå **Faltaba**: Comprensi√≥n evolutiva

### **La Brecha Cognitiva**
Como se detalla en `MOTIVATION_es.md`, la lectura humana de documentos complejos involucra:
1. **Primera pasada**: Lectura progresiva + **refinamiento continuo** de la comprensi√≥n
2. **Segunda pasada**: Re-lectura con **contexto global** para enriquecer la comprensi√≥n

Este proceso es **esencial** para el objetivo central del proyecto: generar datasets de alta calidad para el libro "3 pasos contra el sedentarismo" que preserven la voz y metodolog√≠a del autor.

### **Soluci√≥n v2.0**
Implementar lo **absolutamente m√≠nimo** para demostrar lectura cognitiva vs. chunks fragmentados:
- ‚úÖ Lectura de dos pasadas (progresiva + enriquecimiento simple)
- ‚úÖ Refinamiento b√°sico de res√∫menes cuando la comprensi√≥n cambia significativamente
- ‚úÖ Contexto acumulado en lugar de chunks aislados
- ‚úÖ Enriquecimiento simple de segunda pasada con contexto global

**Todo lo dem√°s** (detecci√≥n de emergencia, seguimiento complejo de refinamiento, grafos de conocimiento) permanece en fases futuras.

---

## üß† Prop√≥sito y Visi√≥n

**Cognitive Document Reader v2** es una librer√≠a Python que simula aut√©nticamente la lectura de documentos similar a la humana a trav√©s de **procesamiento cognitivo de dos pasadas** con **comprensi√≥n evolutiva**. Esta versi√≥n implementa completamente el enfoque de lectura cognitiva detallado en `MOTIVATION_es.md`.

---

## üõ†Ô∏è Stack Tecnol√≥gico y Est√°ndares de Desarrollo

### **Stack Tecnol√≥gico Principal**

**Lenguaje y Runtime:**
- **Python 3.12+**: Caracter√≠sticas modernas de Python con excelente soporte de tipos
- **Async/Await**: Preferir programaci√≥n as√≠ncrona para operaciones limitadas por I/O

**Herramientas de Desarrollo:**
- **uv**: Gesti√≥n de dependencias y configuraci√≥n de proyecto (reemplaza Poetry, pip, venv)
- **ruff**: Linting y formateo de c√≥digo (reemplaza black, isort, flake8)
- **mypy**: Verificaci√≥n est√°tica de tipos con configuraci√≥n estricta
- **pytest**: Framework de testing con soporte as√≠ncrono

**Librer√≠as de Dominio:**
- **pydantic v2+**: Validaci√≥n de datos y gesti√≥n de configuraci√≥n
- **docling**: Parseado universal de documentos (estable actual: v2.43.0+)
- **aiohttp**: Cliente HTTP as√≠ncrono para comunicaciones LLM
- **click**: Framework de interfaz de l√≠nea de comandos
- **langdetect**: Capacidades de detecci√≥n de idioma

### **Est√°ndares de Calidad de C√≥digo (Obligatorios)**

**Seguridad de Tipos:**
- **TODAS** las funciones, m√©todos y miembros de clase DEBEN tener anotaciones de tipo
- Usar `from __future__ import annotations` para referencias futuras
- Preferir tipos espec√≠ficos sobre gen√©ricos (`List[str]` sobre `List[Any]`)

**Documentaci√≥n:**
- **TODAS** las funciones, m√©todos y clases p√∫blicas DEBEN tener docstrings estilo Google
- Incluir prop√≥sito, par√°metros, valores de retorno, excepciones y ejemplos de uso
- Comentarios de c√≥digo solo en ingl√©s

**Manejo de Excepciones:**
- Usar tipos espec√≠ficos de excepci√≥n, nunca `except:` desnudo
- Crear clases de excepci√≥n personalizadas para errores espec√≠ficos del dominio
- Proporcionar mensajes de error informativos sin exponer datos sensibles

### **Principios de Arquitectura y Dise√±o**

**Patrones de Dise√±o:**
- **Responsabilidad √önica**: Cada m√≥dulo/clase tiene una responsabilidad clara
- **Composici√≥n sobre Herencia**: Favorecer composici√≥n e inyecci√≥n de dependencias
- **Expl√≠cito sobre Impl√≠cito**: Evitar valores m√°gicos, ser expl√≠cito sobre dependencias
- **Async-First**: Dise√±ar APIs para ser compatibles con async desde el inicio

**Gesti√≥n de Configuraci√≥n:**
- **Dirigido por ambiente**: Toda configuraci√≥n v√≠a variables de entorno
- **Validaci√≥n Pydantic**: Usar modelos Pydantic para validaci√≥n de configuraci√≥n
- **Amigable para desarrollo**: Incluir modos dry-run y respuestas mock
- **Sin valores hardcodeados**: Todo configurable

**Filosof√≠a de Testing:**
- **90% cobertura m√≠nima**: Enfocarse en rutas cr√≠ticas y manejo de errores
- **Mock de dependencias externas**: Llamadas LLM, I/O de archivos, requests de red
- **R√°pido y determinista**: Tests deben ejecutarse r√°pidamente y consistentemente
- **Probar escenarios de √©xito y fallo**

### **Est√°ndares de Estructura de Proyecto**

**Organizaci√≥n de Directorios:**
```
cognitive-document-reader/
‚îú‚îÄ‚îÄ src/cognitive_reader/         # Paquete principal de c√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # Exportaciones API p√∫blica
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Modelos de datos Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ core/                     # L√≥gica principal de lectura cognitiva  
‚îÇ   ‚îú‚îÄ‚îÄ parsers/                  # Componentes de parseado de documentos
‚îÇ   ‚îú‚îÄ‚îÄ llm/                      # Integraci√≥n LLM
‚îÇ   ‚îú‚îÄ‚îÄ utils/                    # Funciones utilitarias
‚îÇ   ‚îî‚îÄ‚îÄ cli/                      # Interfaz de l√≠nea de comandos
‚îú‚îÄ‚îÄ tests/                        # Suite de tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/                     # Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ integration/              # Tests de integraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                 # Datos de prueba y fixtures
‚îú‚îÄ‚îÄ examples/                     # Ejemplos de uso y demos
‚îú‚îÄ‚îÄ pyproject.toml                # Configuraci√≥n de proyecto (formato uv)
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n en ingl√©s
‚îî‚îÄ‚îÄ .env.example                  # Plantilla de configuraci√≥n de entorno
```

**Convenciones de Nomenclatura de Archivos:**
- **Snake_case**: Todos los archivos y directorios Python
- **Prop√≥sito claro**: Los nombres de archivos deben indicar funcionalidad
- **Sin abreviaciones**: Preferir `progressive_reader.py` sobre `prog_reader.py`
- **Test espejo**: Archivos de test reflejan estructura fuente (`test_progressive_reader.py`)

**Responsabilidades de M√≥dulos:**
- **models/**: Solo modelos Pydantic y estructuras de datos
- **core/**: L√≥gica de negocio y algoritmos de procesamiento cognitivo  
- **parsers/**: Manejo de formatos de documento y detecci√≥n de estructura
- **llm/**: Comunicaci√≥n LLM y gesti√≥n de prompts
- **utils/**: Funciones puras sin dependencias externas
- **cli/**: Interfaz de l√≠nea de comandos e interacci√≥n del usuario

---

## üéØ Casos de Uso Principales

### **1. Res√∫menes de Alta Calidad para Lectura/Estudio Humano**
   - Res√∫menes que evolucionan durante el proceso de lectura  
   - Mapas contextuales mostrando desarrollo del conocimiento
   - Rutas de aprendizaje progresivo a trav√©s de documentos complejos

### **2. Generaci√≥n de Dataset para Fine-tuning**
   - **Construcci√≥n de contexto jer√°rquico**: Res√∫menes Libro ‚Üí Cap√≠tulo ‚Üí Secci√≥n para entrenamiento coherente
   - **Terminolog√≠a consistente**: Definiciones de conceptos refinadas cognitivamente para precisi√≥n del dominio
   - **Ejemplos de entrenamiento ricos**: Usar jerarqu√≠a de res√∫menes para generar pares Q&A contextualmente coherentes

### üß† **Innovaci√≥n Principal: Procesamiento Cognitivo de Dos Pasadas**

A diferencia de los procesadores de documentos tradicionales que fragmentan contenido, **Cognitive Document Reader v2** implementa el proceso completo de lectura humana:

#### üîÑ **Primera Pasada: Construcci√≥n Progresiva + Refinamiento Continuo**
1. **Lectura progresiva secuencial** con acumulaci√≥n de contexto
2. **Res√∫menes evolutivos** que se actualizan cuando se encuentra nueva informaci√≥n
3. **Refinamiento jer√°rquico** donde subsecciones actualizan secciones padre
4. **Detecci√≥n de conceptos emergentes** cuando las ideas se vuelven claras con contexto
5. **Procesamiento r√°pido** usando modelo veloz para simular "primera lectura r√°pida" humana

#### üîç **Segunda Pasada: Enriquecimiento Contextual**
1. **Re-lectura informada** con comprensi√≥n completa del documento
2. **Identificaci√≥n de conexiones profundas** entre conceptos previamente separados
3. **Mejora de relaciones** que solo se vuelve visible con contexto completo
4. **S√≠ntesis final** integrando todo el conocimiento coherentemente
5. **Procesamiento de calidad** usando modelo cuidadoso para simular "an√°lisis reflexivo" humano

### üß† **Estrategia de Modelo Dual: Simulando Patrones de Lectura Humana**

La lectura humana naturalmente involucra dos enfoques cognitivos diferentes:
- **Escaneo r√°pido**: Vista general r√°pida para captar la idea general (primera pasada)
- **An√°lisis cuidadoso**: Comprensi√≥n detallada con contexto completo (segunda pasada)

La **configuraci√≥n de modelo dual** refleja esto:
- **Modelo r√°pido (primera pasada)**: Optimizado para velocidad, comprensi√≥n b√°sica, detecci√≥n r√°pida de refinamiento
- **Modelo de calidad (segunda pasada)**: Optimizado para profundidad, comprensi√≥n matizada, enriquecimiento sofisticado

Este enfoque **mejora tanto el rendimiento como la precisi√≥n** al ajustar los recursos computacionales a los requisitos cognitivos.

---

## üèóÔ∏è Principios de Dise√±o v2

- **Simulaci√≥n Cognitiva Aut√©ntica**: Proceso verdadero de lectura de dos pasadas imitando cognici√≥n humana
- **Comprensi√≥n Evolutiva**: Conocimiento que cambia y mejora durante el procesamiento
- **Refinamiento Jer√°rquico**: Actualizaci√≥n continua desde subsecciones hasta comprensi√≥n global
- **Inteligencia Emergente**: Conceptos y relaciones que aparecen con contexto acumulado
- **Trazabilidad de Refinamiento**: Historial completo de c√≥mo evolucion√≥ la comprensi√≥n
- **Minimizar Llamadas LLM**: Batching inteligente y reutilizaci√≥n de contexto a trav√©s de ambas pasadas
- **Preservaci√≥n de Calidad**: Mantener fidelidad a la voz y metodolog√≠a del autor original

---

## üöÄ MVP v2.0 - Lectura Cognitiva M√≠nima

### **Objetivo Principal**: Demostrar lectura cognitiva vs. chunks fragmentados con complejidad m√≠nima

**Objetivo MVP**: Lectura cognitiva de dos pasadas **m√≠nima** para probar el concepto con implementaci√≥n limpia y enfocada

### ‚úÖ **Caracter√≠sticas Principales MVP v2** (M√≠nimo Absoluto)

#### 1. **Lectura de Dos Pasadas** (Esencial)
   - **Primera Pasada**: Lectura progresiva con contexto acumulado (como primera lectura humana)
   - **Segunda Pasada**: Re-leer con contexto completo para enriquecer comprensi√≥n (como segunda lectura humana)
   - **Eso es todo**: Probar que funciona diferente a sistemas basados en chunks

#### 2. **Refinamiento B√°sico** (Cuando Obviamente se Necesita)
   - **Disparador simple**: Si nueva secci√≥n cambia significativamente comprensi√≥n de secci√≥n previa, actualizarla
   - **Sin seguimiento complejo**: Solo res√∫menes "antes" y "despu√©s"
   - **Umbral manual**: Disparador simple basado en confianza

#### 3. **Contexto Acumulado** (Diferencia Principal)
   - **Contexto progresivo**: Cada secci√≥n procesada con todo el contexto previo
   - **Enriquecimiento global**: Segunda pasada usa comprensi√≥n completa del documento
   - **Sin chunks**: Evitar comprensi√≥n fragmentada

#### 4. **Salida M√≠nima** (Probar Concepto)
   - **JSON limpio**: Res√∫menes jer√°rquicos y conceptos refinados sin metadata de proceso
   - **Calidad evidente**: El output debe mostrar claramente sus ventajas (res√∫menes coherentes, conceptos definidos, jerarqu√≠a l√≥gica)
   - **Enfoque en valor**: Solo la informaci√≥n √∫til para RAG/Fine-tuning, sin ruido del proceso interno

#### 5. **Esenciales de Desarrollo** (Para Testing)
   - **Modo dry-run**: Probar sin costos LLM
   - **Logging interno**: Solo para debugging durante desarrollo
   - **Configuraci√≥n**: Habilitar/deshabilitar segunda pasada y refinamiento

### üéØ **Criterios de √âxito para MVP v2**

- ‚úÖ **Prueba de concepto**: Output que evidencie calidad superior (res√∫menes coherentes vs. chunks fragmentados)
- ‚úÖ **Test "3 pasos"**: Procesar exitosamente el libro con enfoque cognitivo
- ‚úÖ **Calidad cognitiva**: Res√∫menes que muestren comprensi√≥n profunda e integrada del contenido
- ‚úÖ **Beneficio de contexto**: Demostrar valor del contexto acumulado vs. fragmentos

---

## üóÉÔ∏è Modelos de Datos v2

### **Principio Principal**: Definir contratos claros mientras se permite flexibilidad de implementaci√≥n

```python
from __future__ import annotations
from enum import Enum
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field, ConfigDict

class LanguageCode(str, Enum):
    """Idiomas soportados para procesamiento de documentos"""
    AUTO = "auto"  # Detecci√≥n autom√°tica
    EN = "en"      # Ingl√©s
    ES = "es"      # Espa√±ol

class DocumentSection(BaseModel):
    """Secci√≥n de documento con estructura jer√°rquica"""
    model_config = ConfigDict(frozen=True)
    
    id: str                                    # Identificador √∫nico de secci√≥n
    title: str                                 # T√≠tulo de secci√≥n (limpio)
    content: str                               # Contenido de texto de secci√≥n
    level: int                                 # Nivel jer√°rquico (0=documento, 1=cap√≠tulo, 2=secci√≥n, etc.)
    parent_id: Optional[str] = None            # ID de secci√≥n padre (None para ra√≠z)
    children_ids: List[str] = Field(default_factory=list)  # IDs de secciones hijas
    order_index: int                           # Orden dentro del padre

class SectionSummary(BaseModel):
    """Resumen de secci√≥n optimizado para chunks RAG"""
    section_id: str                            # Referencia a DocumentSection.id
    title: str                                 # T√≠tulo de secci√≥n
    summary: str                               # Resumen mejorado cognitivamente (optimizado para chunks RAG)
    key_concepts: List[str] = Field(default_factory=list)  # IDs de conceptos clave relevantes a esta secci√≥n
    summary_length: int                        # Longitud del resumen en caracteres

class ConceptDefinition(BaseModel):
    """Concepto clave con definici√≥n refinada cognitivamente"""
    concept_id: str                            # Identificador √∫nico (ej: "sedentarismo", "movimiento_natural")
    name: str                                  # Nombre legible del concepto
    definition: str                            # Definici√≥n refinada cognitivamente
    first_mentioned_in: str                    # ID de secci√≥n donde se identific√≥ este concepto primero
    relevant_sections: List[str] = Field(default_factory=list)  # IDs de secci√≥n donde el concepto es relevante

class CognitiveKnowledge(BaseModel):
    """Conocimiento completo extra√≠do con procesamiento cognitivo para RAG/Fine-tuning"""
    # Identificaci√≥n de documento
    document_title: str
    document_summary: str                      # Resumen mejorado cognitivamente a nivel documento
    detected_language: LanguageCode
    
    # Res√∫menes jer√°rquicos optimizados para chunks RAG
    hierarchical_summaries: Dict[str, SectionSummary]  # Mapeo ID Secci√≥n -> Resumen
    
    # Conceptos clave con definiciones refinadas cognitivamente
    concepts: Dict[str, ConceptDefinition]     # Mapeo ID Concepto -> Definici√≥n
    
    # √çndices de navegaci√≥n jer√°rquica
    hierarchy_index: Dict[str, List[str]] = Field(default_factory=dict)  # Nivel -> IDs de Secci√≥n
    parent_child_map: Dict[str, List[str]] = Field(default_factory=dict)  # ID Padre -> IDs Hijos
    
    # Estad√≠sticas de res√∫menes
    total_sections: int = 0
    avg_summary_length: int = 0
    total_concepts: int = 0
    
    # Metadatos opcionales de procesamiento
    processing_metadata: Dict[str, Any] = Field(default_factory=dict)

class CognitiveConfig(BaseModel):
    """Configuraci√≥n para lectura cognitiva de documentos"""
    
    # Configuraci√≥n LLM
    model_name: str = Field(default="qwen3:8b", description="Nombre del modelo LLM por defecto (usado cuando no se configuran modelos duales)")
    temperature: float = Field(default=0.1, ge=0.0, le=2.0, description="Temperatura LLM")
    
    # Configuraci√≥n de Modelo Dual - Simula patrones de lectura humana
    # Configuraci√≥n multi-pasada (dise√±o extensible)
    max_passes: int = Field(default=2, ge=1, le=10, description="N√∫mero m√°ximo de pasadas cognitivas")
    convergence_threshold: float = Field(default=0.1, ge=0.01, le=1.0, description="Umbral para detectar cu√°ndo pasadas adicionales a√±aden valor m√≠nimo")
    
    # Estrategia de modelo dual: scan r√°pido + procesamiento de calidad
    enable_fast_first_pass: bool = Field(default=True, description="Usar modelo r√°pido para scan inicial")
    fast_pass_model: Optional[str] = Field(default="llama3.1:8b", description="Modelo r√°pido para scan inicial del documento")
    main_model: Optional[str] = Field(default="qwen3:8b", description="Modelo de calidad para procesamiento cognitivo detallado")
    
    # Configuraci√≥n de temperatura
    fast_pass_temperature: Optional[float] = Field(default=0.1, ge=0.0, le=2.0, description="Temperatura para scan r√°pido")
    main_pass_temperature: Optional[float] = Field(default=0.3, ge=0.0, le=2.0, description="Temperatura para procesamiento de calidad")

### **üîß Filosof√≠a de Dise√±o Multi-Pasada Extensible**

El MVP implementa **lectura de 2 pasadas** pero est√° arquitecturalmente preparado para **extensi√≥n a N pasadas**:

```python
# Uso MVP (2 pasadas) - Listo hoy
config = CognitiveConfig(
    max_passes=2,
    fast_pass_model="llama3.1:8b",    # Scan inicial r√°pido
    main_model="qwen3:8b"          # Procesamiento cognitivo de calidad
)

# Uso futuro N-pasadas (misma API) - Extensi√≥n fluida
config = CognitiveConfig(
    max_passes=4,                     # Profundidad configurable
    convergence_threshold=0.05,       # Optimizaci√≥n auto-stop  
    main_model="qwen3:8b"          # Mismo modelo, contexto m√°s rico cada pasada
)
```

#### **Principios Clave de Dise√±o**

1. **üìñ Mismo "Cerebro", Mejor Conocimiento**: M√∫ltiples pasadas usan el **mismo modelo** con **contexto progresivamente m√°s rico**
2. **üîÑ Acumulaci√≥n de Contexto**: Cada pasada proporciona res√∫menes, conceptos e insights acumulados a la siguiente
3. **üèÜ Autoridad del Texto Original**: **El texto fuente siempre tiene precedencia** sobre res√∫menes/contexto previo cuando hay conflictos
4. **‚ö° Balance Inteligente Velocidad/Calidad**: Scan r√°pido (`llama3.1:8b`) + Procesamiento de calidad (`qwen3:8b`) 
5. **üéØ Detecci√≥n de Convergencia**: Futuro auto-stop cuando pasadas adicionales a√±aden valor m√≠nimo
6. **üèóÔ∏è Consistencia de API**: Misma interfaz escala de MVP 2-pasadas a caracter√≠sticas avanzadas N-pasadas

#### **üèÜ Principio de Autoridad del Texto Fuente**

**CR√çTICO**: Al procesar cada secci√≥n, el **texto original** es la autoridad suprema:

```python
# Jerarqu√≠a de prompting (mayor a menor autoridad)
AUTHORITY_HIERARCHY = [
    "Contenido del texto original",    # ü•á Autoridad suprema - siempre gana
    "Res√∫menes refinados previos",     # ü•à Gu√≠a contextual  
    "Conceptos descubiertos",          # ü•â Informaci√≥n de apoyo
    "Comprensi√≥n global del documento" # üìö Contexto de fondo
]
```

**Estrategia de Resoluci√≥n de Conflictos**:
- ‚úÖ **Texto contradice resumen** ‚Üí Actualizar resumen para coincidir con texto
- ‚úÖ **Texto a√±ade nuevo matiz** ‚Üí Enriquecer resumen con perspectiva del texto  
- ‚úÖ **Texto revela error en concepto** ‚Üí Refinar definici√≥n del concepto
- ‚ùå **Nunca** modificar interpretaci√≥n del texto para ajustarse al contexto previo

#### **üí≠ Estrategia de Prompting Consciente de Autoridad**

**Estructura de Prompt de Ejemplo** (aplicando autoridad del texto):

```
CONTEXTO (solo para informaci√≥n de fondo):
- Resumen del Libro: [comprensi√≥n previa]
- Definiciones de Conceptos: [descubiertas hasta ahora]  
- Resumen de Secci√≥n Padre: [si aplica]

TEXTO FUENTE (AUTORITATIVO):
[contenido real de la secci√≥n a procesar]

INSTRUCCIONES:
1. Lee el TEXTO FUENTE cuidadosamente - esta es tu fuente PRIMARIA de verdad
2. Usa el CONTEXTO solo como informaci√≥n de fondo para informar tu comprensi√≥n
3. Si el TEXTO FUENTE contradice cualquier informaci√≥n del CONTEXTO:
   - Conf√≠a completamente en el TEXTO FUENTE
   - Actualiza tu comprensi√≥n basada en el TEXTO FUENTE
   - Nota las discrepancias para refinamiento
4. Genera resumen que refleje el TEXTO FUENTE con precisi√≥n
5. Identifica conceptos mencionados en el TEXTO FUENTE (no solo del contexto)

CR√çTICO: El TEXTO FUENTE siempre es correcto. Los res√∫menes previos pueden contener errores o comprensi√≥n incompleta.
```

#### **üìù Ejemplo Pr√°ctico: Autoridad del Texto en Acci√≥n**

**Escenario**: Procesando cap√≠tulo 3 de "3 pasos contra el sedentarismo"

```python
# Contexto previo (puede contener errores)
resumen_previo = {
    "sedentarismo": "Falta de ejercicio f√≠sico en la vida moderna"  # ‚Üê Comprensi√≥n incompleta
}

# Texto de secci√≥n actual (autoritativo)
texto_fuente = """
El sedentarismo, en su sentido m√°s profundo, no es simplemente pasar mucho tiempo sentado. 
Es un concepto arraigado en la falta de movimiento variado y en la especializaci√≥n de las posturas.
"""

# Resultado del procesamiento cognitivo (autoridad del texto aplicada)
comprension_refinada = {
    "sedentarismo": "Estado cr√≥nico de inactividad f√≠sica que resulta de la falta de movimiento variado y especializaci√≥n de posturas, no simplemente pasar tiempo sentado"  # ‚Üê Corregido por texto fuente
}
```

**Insight Clave**: El texto fuente **corrigi√≥** la definici√≥n previa incompleta, demostrando c√≥mo la autoridad del texto asegura precisi√≥n evolutiva.

---

## üîÑ **Prop√≥sito Central: Correcci√≥n de Errores y Refinamiento**

### **üéØ Justificaci√≥n Principal del Dise√±o Multi-Pasada**

La **raz√≥n principal** para segunda, tercera y N-√©sima pasadas es **correcci√≥n sistem√°tica de errores y refinamiento del conocimiento**:

#### **üîç Qu√© Se Corrige/Refina**

1. **üìù Precisi√≥n de Res√∫menes**
   - **Errores iniciales**: Los res√∫menes de primera pasada pueden perder puntos clave o malinterpretar conceptos
   - **Refinamiento progresivo**: Cada pasada corrige y enriquece la comprensi√≥n
   - **Coherencia global**: Secciones posteriores proporcionan contexto que clarifica malentendidos previos

2. **üí° Definiciones de Conceptos**
   - **Aproximaciones iniciales**: Primeros encuentros con conceptos generan definiciones parciales
   - **Precisi√≥n iterativa**: Pasadas subsecuentes refinan definiciones con contexto m√°s rico
   - **Validaci√≥n cruzada**: Conceptos mencionados en varias secciones obtienen definiciones m√°s precisas

3. **üîó Comprensi√≥n de Relaciones** 
   - **Conexiones perdidas**: Procesamiento de una sola pasada pierde relaciones entre conceptos
   - **Patrones emergentes**: Multi-pasada revela c√≥mo se relacionan conceptos a trav√©s del documento
   - **Claridad jer√°rquica**: Relaciones padre-hijo entre conceptos se vuelven aparentes

#### **üìà Ejemplos de Correcci√≥n en Uso Real**

```python
# Pasada 1: Comprensi√≥n inicial (a menudo incompleta/incorrecta)
concepto_primera_pasada = {
    "sedentarismo": "Falta de ejercicio f√≠sico"  # ‚Üê Comprensi√≥n superficial
}

# Pasada 2: Corregida con contexto global
concepto_segunda_pasada = {
    "sedentarismo": "Estado cr√≥nico de inactividad f√≠sica caracterizado por falta de movimiento variado y especializaci√≥n de posturas, no simplemente ausencia de ejercicio"  # ‚Üê Comprensi√≥n profunda y precisa
}

# Pasada 3: Refinada adicionalmenre con referencias cruzadas
concepto_tercera_pasada = {
    "sedentarismo": "Estado cr√≥nico de inactividad f√≠sica que resulta de entornos modernos que eliminan movimiento variado, causando adaptaciones corporales problem√°ticas mediante especializaci√≥n postural. Se diferencia de la simple falta de ejercicio por su enfoque en variedad de movimiento vs. intensidad."  # ‚Üê Comprensi√≥n integral y matizada
}
```

#### **‚úÖ Indicadores de √âxito para Refinamiento**

- **Evoluci√≥n de conceptos**: Definiciones se vuelven m√°s precisas y comprehensivas entre pasadas
- **Detecci√≥n de errores**: Sistema identifica y corrige malentendidos previos  
- **Mejora de coherencia**: Res√∫menes se alinean mejor con mensaje general del documento
- **Claridad de relaciones**: Conexiones entre conceptos se vuelven expl√≠citas y precisas
    
    # Procesamiento de Documentos
    chunk_size: int = Field(default=1000, gt=100, description="Tama√±o de chunk de texto para procesamiento")
    chunk_overlap: int = Field(default=200, ge=0, description="Solapamiento entre chunks")
    context_window: int = Field(default=4096, gt=0, description="L√≠mite de ventana de contexto LLM")
    
    # Configuraciones de Rendimiento
    timeout_seconds: int = Field(default=120, gt=0, description="Timeout de request")
    max_retries: int = Field(default=3, ge=0, description="M√°ximo intentos de retry")
    document_language: LanguageCode = Field(default=LanguageCode.AUTO, description="Idioma del documento")
    
    # Caracter√≠sticas Cognitivas
    enable_second_pass: bool = Field(default=True, description="Habilitar enriquecimiento de segunda pasada")
    enable_refinement: bool = Field(default=True, description="Habilitar refinamiento de primera pasada")
    refinement_threshold: float = Field(
        default=0.4, 
        ge=0.0, 
        le=1.0, 
        description="Umbral para disparar refinamiento (0.0=nunca, 1.0=siempre)"
    )
    
    # Caracter√≠sticas de Desarrollo
    dry_run: bool = Field(default=False, description="Ejecutar sin llamadas LLM")
    mock_responses: bool = Field(default=False, description="Usar respuestas mock")
    
    # Carga de variables de entorno
    @classmethod
    def from_env(cls) -> "CognitiveConfig":
        """Crear configuraci√≥n desde variables de entorno con fallback a defaults"""
        import os
        return cls(
            # Configuraciones LLM
            model_name=os.getenv("COGNITIVE_READER_MODEL", "qwen3:8b"),
            temperature=float(os.getenv("COGNITIVE_READER_TEMPERATURE", "0.1")),
            
            # Configuraci√≥n multi-pasada (dise√±o extensible)
            max_passes=int(os.getenv("COGNITIVE_READER_MAX_PASSES", "2")),
            convergence_threshold=float(os.getenv("COGNITIVE_READER_CONVERGENCE_THRESHOLD", "0.1")),
            
            # Configuraciones de modelo dual (scan r√°pido + procesamiento de calidad)
            enable_fast_first_pass=os.getenv("COGNITIVE_READER_ENABLE_FAST_FIRST_PASS", "true").lower() == "true",
            fast_pass_model=os.getenv("COGNITIVE_READER_FAST_PASS_MODEL", "llama3.1:8b"),
            main_model=os.getenv("COGNITIVE_READER_MAIN_MODEL", "qwen3:8b"),
            fast_pass_temperature=float(os.getenv("COGNITIVE_READER_FAST_PASS_TEMPERATURE", "0.1")) if os.getenv("COGNITIVE_READER_FAST_PASS_TEMPERATURE") else None,
            main_pass_temperature=float(os.getenv("COGNITIVE_READER_MAIN_PASS_TEMPERATURE", "0.3")) if os.getenv("COGNITIVE_READER_MAIN_PASS_TEMPERATURE") else None,
            
            # Configuraciones de procesamiento
            chunk_size=int(os.getenv("COGNITIVE_READER_CHUNK_SIZE", "1000")),
            chunk_overlap=int(os.getenv("COGNITIVE_READER_CHUNK_OVERLAP", "200")),
            context_window=int(os.getenv("COGNITIVE_READER_CONTEXT_WINDOW", "4096")),
            
            # Configuraciones de rendimiento
            timeout_seconds=int(os.getenv("COGNITIVE_READER_TIMEOUT_SECONDS", "120")),
            max_retries=int(os.getenv("COGNITIVE_READER_MAX_RETRIES", "3")),
            document_language=LanguageCode(os.getenv("COGNITIVE_READER_LANGUAGE", "auto")),
            
            # Caracter√≠sticas cognitivas
            enable_second_pass=os.getenv("COGNITIVE_READER_ENABLE_SECOND_PASS", "true").lower() == "true",
            enable_refinement=os.getenv("COGNITIVE_READER_ENABLE_REFINEMENT", "true").lower() == "true",
            refinement_threshold=float(os.getenv("COGNITIVE_READER_REFINEMENT_THRESHOLD", "0.4")),
            
            # Caracter√≠sticas de desarrollo
            dry_run=os.getenv("COGNITIVE_READER_DRY_RUN", "false").lower() == "true",
            mock_responses=os.getenv("COGNITIVE_READER_MOCK_RESPONSES", "false").lower() == "true",
        )

# Referencia de Variables de Entorno
COGNITIVE_READER_ENV_VARS = {
    # Configuraci√≥n LLM
    "COGNITIVE_READER_MODEL": "Nombre del modelo LLM por defecto (default: qwen3:8b)",
    "COGNITIVE_READER_TEMPERATURE": "Temperatura LLM por defecto 0.0-2.0 (default: 0.1)",
    
    # Configuraci√≥n Multi-pasada (Dise√±o Extensible)
    "COGNITIVE_READER_MAX_PASSES": "N√∫mero m√°ximo de pasadas cognitivas (default: 2)",
    "COGNITIVE_READER_CONVERGENCE_THRESHOLD": "Umbral para auto-detener pasadas cuando mejora m√≠nima (default: 0.1)",
    
    # Estrategia de Modelo Dual (Scan R√°pido + Procesamiento de Calidad)
    "COGNITIVE_READER_ENABLE_FAST_FIRST_PASS": "Habilitar modelo r√°pido para scan inicial (default: true)",
    "COGNITIVE_READER_FAST_PASS_MODEL": "Modelo r√°pido para scan inicial del documento (default: llama3.1:8b)",
    "COGNITIVE_READER_MAIN_MODEL": "Modelo de calidad para procesamiento cognitivo detallado (default: qwen3:8b)",
    "COGNITIVE_READER_FAST_PASS_TEMPERATURE": "Temperatura para scan r√°pido (default: 0.1)",
    "COGNITIVE_READER_MAIN_PASS_TEMPERATURE": "Temperatura para procesamiento de calidad (default: 0.3)",
    
    # Configuraci√≥n de Procesamiento  
    "COGNITIVE_READER_CHUNK_SIZE": "Tama√±o de chunk de texto (default: 1000)",
    "COGNITIVE_READER_CHUNK_OVERLAP": "Solapamiento de chunk (default: 200)",
    "COGNITIVE_READER_CONTEXT_WINDOW": "L√≠mite de contexto LLM (default: 4096)",
    "COGNITIVE_READER_LANGUAGE": "Idioma documento auto/en/es (default: auto)",
    
    # Caracter√≠sticas Cognitivas
    "COGNITIVE_READER_ENABLE_SECOND_PASS": "Habilitar segunda pasada true/false (default: true)",
    "COGNITIVE_READER_ENABLE_REFINEMENT": "Habilitar refinamiento true/false (default: true)",
    "COGNITIVE_READER_REFINEMENT_THRESHOLD": "Umbral refinamiento 0.0-1.0 (default: 0.4)",
    
    # Rendimiento y Desarrollo
    "COGNITIVE_READER_TIMEOUT_SECONDS": "Timeout de request (default: 120)",
    "COGNITIVE_READER_MAX_RETRIES": "Max retries (default: 3)",
    "COGNITIVE_READER_DRY_RUN": "Modo dry run true/false (default: false)",
    "COGNITIVE_READER_MOCK_RESPONSES": "Respuestas mock true/false (default: false)",
}
```

### üìö **Requisitos de API**

**Interfaz Principal**:
- Interfaz principal: `read_document(file_path, config) -> CognitiveKnowledge`
- Soporte de configuraci√≥n via variables de entorno
- API simple y limpia enfocada en caracter√≠sticas cognitivas

**Opciones de Configuraci√≥n**:
- `enable_second_pass`: Boolean para habilitar/deshabilitar enriquecimiento de segunda pasada
- `enable_refinement`: Boolean para habilitar/deshabilitar refinamiento de primera pasada  
- `refinement_threshold`: Float (0.0-1.0) para controlar sensibilidad de refinamiento
- Configuraci√≥n de modelo dual para procesamiento r√°pido/calidad

**Datos de Retorno**:
- Estad√≠sticas completas de procesamiento cognitivo (refinamientos hechos, enriquecimientos hechos)
- Indicaci√≥n clara de qu√© secciones fueron procesadas con caracter√≠sticas cognitivas
- Metadatos de procesamiento incluyendo modelos usados para cada pasada
- Seguimiento de evoluci√≥n cognitiva e historial de refinamiento

---

## üèóÔ∏è Arquitectura Cognitiva v2

### **Componentes del Sistema**

```
CognitiveReader (Motor Principal)
‚îú‚îÄ‚îÄ StructureDetector (an√°lisis y detecci√≥n de estructura de documentos)
‚îú‚îÄ‚îÄ ProgressiveReader (mejorado con capacidad de refinamiento)
‚îú‚îÄ‚îÄ ContextualEnricher (nuevo componente para segunda pasada)
‚îî‚îÄ‚îÄ CognitiveSynthesizer (mejorado con metadatos cognitivos)
```

### **Responsabilidades de Componentes**

#### **CognitiveReader** (Orquestador Principal)
**Prop√≥sito**: Coordinar proceso de lectura cognitiva de dos pasadas

**Responsabilidades**:
- Orquestar flujo completo de lectura de dos pasadas
- Gestionar configuraci√≥n para caracter√≠sticas cognitivas (refinamiento, segunda pasada)
- Coordinar entre procesamiento de primera pasada y segunda pasada
- Proporcionar API limpia enfocada en caracter√≠sticas cognitivas
- Rastrear y reportar m√©tricas de procesamiento cognitivo

**Requisitos de Interfaz**:
- `read_document(file_path, config) -> CognitiveKnowledge`: Interfaz primaria para lectura cognitiva
- API limpia enfocada en caracter√≠sticas cognitivas
- Estad√≠sticas comprehensivas de procesamiento cognitivo en resultados

#### **ProgressiveReader** (Mejorado)
**Prop√≥sito**: Ejecutar primera pasada con lectura progresiva y capacidad de refinamiento

**Responsabilidades**:
- Procesar secciones secuencialmente con contexto acumulado
- Detectar cuando nuevo contexto cambia significativamente comprensi√≥n de secciones previas
- Actualizar res√∫menes de secciones previas cuando se necesita refinamiento
- Rastrear eventos de refinamiento y razones
- Mantener acumulaci√≥n de contexto a trav√©s del procesamiento de secciones

**Requisitos**:
- Capacidad de refinamiento configurable (habilitar/deshabilitar)
- Configuraci√≥n de umbral de refinamiento
- Seguimiento completo de qu√© secciones fueron refinadas y por qu√©
- Procesamiento eficiente con contexto acumulado

#### **ContextualEnricher** (Nuevo Componente)
**Prop√≥sito**: Ejecutar enriquecimiento de segunda pasada con contexto global del documento

**Responsabilidades**:
- Re-leer secciones con comprensi√≥n completa del documento
- Identificar oportunidades de enriquecimiento con contexto global
- Generar res√∫menes mejorados que incorporen perspectiva completa del documento
- Distinguir entre enriquecimientos significativos y cambios triviales
- Preservar refinamientos de primera pasada mientras a√±ade insights de segunda pasada

**Requisitos**:
- Debe ser configurable para habilitar/deshabilitar procesamiento de segunda pasada
- Debe trabajar con resultados del ProgressiveReader de primera pasada
- Debe rastrear eventos de enriquecimiento y valor a√±adido
- Debe mantener eficiencia de procesamiento

#### **CognitiveSynthesizer** (Mejorado)
**Prop√≥sito**: Generar s√≠ntesis final del documento con conciencia de procesamiento cognitivo

**Responsabilidades**:
- Crear s√≠ntesis jer√°rquica del documento
- Incorporar metadatos de procesamiento cognitivo en resultados finales
- Notar qu√© secciones fueron sometidas a refinamiento o enriquecimiento
- Generar resumen de procesamiento cognitivo para salida

**Requisitos**:
- Calidad superior de s√≠ntesis con caracter√≠sticas cognitivas
- Indicaci√≥n clara de todos los eventos de procesamiento cognitivo en salida
- Resumen comprehensivo de beneficios y evoluci√≥n del procesamiento cognitivo

---

## üîÑ Requisitos de Proceso Cognitivo

### **Flujo de Procesamiento de Dos Pasadas**

```
Entrada de Documento
    ‚Üì
Detecci√≥n de Estructura
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PRIMERA PASADA ‚îÇ
‚îÇ Progresiva +    ‚îÇ
‚îÇ Refinamiento    ‚îÇ
‚îÇ B√°sico          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îú‚îÄ‚îÄ Lectura Progresiva ‚îÄ‚îÄ‚Üí Acumulaci√≥n de Contexto
‚îî‚îÄ‚îÄ Refinamiento B√°sico ‚îÄ‚îÄ‚Üí Actualizar res√∫menes si comprensi√≥n cambia
    ‚Üì
Resultado Primera Pasada
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SEGUNDA PASADA ‚îÇ
‚îÇ Contexto Global ‚îÇ
‚îÇ Enriquecimiento ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îú‚îÄ‚îÄ Re-leer con Contexto Global ‚îÄ‚îÄ‚Üí Res√∫menes Mejorados
‚îî‚îÄ‚îÄ Integraci√≥n Simple ‚îÄ‚îÄ‚Üí Conocimiento Final
    ‚Üì
Salida de Conocimiento Cognitivo
```

### **Algoritmo de Procesamiento Jer√°rquico**

El proceso de lectura cognitiva implementa un algoritmo de **s√≠ntesis jer√°rquica bottom-up** que procesa la estructura del documento desde las hojas hasta la ra√≠z, combinando el contenido de cada secci√≥n con los res√∫menes de sus hijos en cada nivel.

#### **Visi√≥n General del Algoritmo**

```
1. An√°lisis de Estructura
   ‚îú‚îÄ‚îÄ Detectar profundidad m√°xima de jerarqu√≠a (o usar l√≠mite especificado por usuario)
   ‚îî‚îÄ‚îÄ Identificar secciones hoja (nivel m√°s profundo, sin hijos)

2. Procesamiento Bottom-Up
   ‚îú‚îÄ‚îÄ PASO 1: Procesar Secciones Hoja
   ‚îÇ   ‚îú‚îÄ‚îÄ Leer contenido de secci√≥n (encabezado + p√°rrafos)
   ‚îÇ   ‚îú‚îÄ‚îÄ Generar resumen de secci√≥n
   ‚îÇ   ‚îî‚îÄ‚îÄ Extraer conceptos clave
   ‚îÇ
   ‚îú‚îÄ‚îÄ PASO 2: Procesar Secciones Contenedoras (nivel por nivel, bottom-up)
   ‚îÇ   ‚îú‚îÄ‚îÄ Combinar: Contenido propio de secci√≥n + Res√∫menes de hijos
   ‚îÇ   ‚îú‚îÄ‚îÄ Generar resumen contenedor del contenido combinado
   ‚îÇ   ‚îî‚îÄ‚îÄ Extraer/fusionar conceptos de contenedor + hijos
   ‚îÇ
   ‚îî‚îÄ‚îÄ PASO 3: Generar Resumen de Documento
       ‚îú‚îÄ‚îÄ Combinar: T√≠tulo del documento + Todos los res√∫menes de nivel superior
       ‚îú‚îÄ‚îÄ Generar resumen a nivel de documento
       ‚îî‚îÄ‚îÄ Crear glosario final de conceptos

3. Generaci√≥n de Salida
   ‚îî‚îÄ‚îÄ Conocimiento Jer√°rquico con √°rbol completo de secciones
```

#### **Ejemplo de Orden de Procesamiento**

Para una estructura de documento como:
```
# T√≠tulo del Libro
## Cap√≠tulo 1: Introducci√≥n
### Secci√≥n 1.1: Antecedentes
### Secci√≥n 1.2: Prop√≥sito
## Cap√≠tulo 2: M√©todos
### Secci√≥n 2.1: Enfoque
```

**Secuencia de procesamiento:**
1. **Procesamiento de hojas**: `Secci√≥n 1.1`, `Secci√≥n 1.2`, `Secci√≥n 2.1` (nivel m√°s profundo primero)
2. **Procesamiento de contenedores**: `Cap√≠tulo 1` (contenido + res√∫menes de 1.1, 1.2), `Cap√≠tulo 2` (contenido + resumen de 2.1)
3. **Procesamiento de documento**: `T√≠tulo del Libro` (contenido + res√∫menes de Cap√≠tulo 1, Cap√≠tulo 2)

#### **Reglas de Composici√≥n de Contenido**

**Para Secciones Hoja:**
- Entrada: `section.content` (encabezado + p√°rrafos siguientes)
- Generar: Resumen de secci√≥n + conceptos clave

**Para Secciones Contenedoras:**
- Entrada: `section.content + child_summaries`
- Formato: `"Contenido de secci√≥n:\n{section.content}\n\nRes√∫menes de subsecciones:\n{child_summaries}"`
- Generar: Resumen contenedor que sintetiza contenido propio con insights de hijos

**Para Nivel de Documento:**
- Entrada: `document_title + top_level_summaries`
- Generar: Resumen de documento + glosario global de conceptos

#### **Implementaci√≥n T√©cnica**

```python
async def process_hierarchically(sections: List[DocumentSection]) -> CognitiveKnowledge:
    """Procesar documento usando s√≠ntesis jer√°rquica bottom-up."""
    
    # 1. Organizar secciones por nivel de jerarqu√≠a
    levels = organize_by_level(sections)
    max_level = max(levels.keys())
    
    # 2. Procesar desde el nivel m√°s profundo hasta la ra√≠z
    summaries = {}
    
    for level in range(max_level, 0, -1):  # Procesamiento bottom-up
        for section in levels[level]:
            if section.children_ids:  # Secci√≥n contenedora
                content = combine_section_and_children_content(section, summaries)
            else:  # Secci√≥n hoja
                content = section.content
                
            summary = await generate_summary(content, section.title)
            summaries[section.id] = summary
    
    # 3. Generar s√≠ntesis a nivel de documento
    document_summary = await generate_document_summary(document_title, top_level_summaries)
    
    return CognitiveKnowledge(...)
```

Este algoritmo asegura que:
- ‚úÖ **Cada secci√≥n** recibe contenido apropiado (texto propio + contexto de hijos)
- ‚úÖ **Orden de procesamiento** sigue dependencia l√≥gica (hijos antes que padres)
- ‚úÖ **Escalabilidad** funciona para cualquier profundidad de estructura de documento
- ‚úÖ **Preservaci√≥n de contexto** mantiene relaciones jer√°rquicas

### **Requisitos de Primera Pasada**

**Requisitos Funcionales:**
- **Lectura Progresiva**: Procesar secciones secuencialmente con contexto acumulado de secciones previas
- **Acumulaci√≥n de Contexto**: Construir contexto comprehensivo mientras progresa la lectura
- **Detecci√≥n de Refinamiento**: Identificar cuando nueva informaci√≥n cambia significativamente comprensi√≥n de secciones previas
- **Actualizaciones de Resumen**: Actualizar res√∫menes de secciones previas cuando evoluciona la comprensi√≥n
- **Seguimiento de Refinamiento**: Registrar qu√© res√∫menes fueron refinados y por qu√©

**Requisitos T√©cnicos:**
- Selecci√≥n y gesti√≥n de modelo r√°pido para optimizaci√≥n de rendimiento
- Umbral de refinamiento configurable v√≠a par√°metro `refinement_threshold`
- Refinamiento puede deshabilitarse v√≠a configuraci√≥n `enable_refinement`
- Seguimiento completo de refinamientos hechos para m√©tricas y an√°lisis

### **Requisitos de Segunda Pasada**

**Requisitos Funcionales:**
- **Re-lectura con Contexto Global**: Re-procesar cada secci√≥n con contexto completo del documento
- **Detecci√≥n de Enriquecimiento**: Identificar casos donde contexto global a√±ade insights significativos
- **Mejora de Resumen**: Mejorar res√∫menes con insights solo disponibles despu√©s de lectura completa
- **Integraci√≥n**: Combinar resultados de primera pasada y segunda pasada coherentemente

**Requisitos T√©cnicos:**
- Segunda pasada puede deshabilitarse v√≠a configuraci√≥n `enable_second_pass`
- Debe detectar y rastrear enriquecimientos significativos vs cambios triviales
- Debe preservar refinamientos de primera pasada mientras a√±ade enriquecimientos
- Debe mantener rendimiento de procesamiento dentro de l√≠mites aceptables

---

## üìä Formatos de Salida Simples v2

### **JSON de Conocimiento Cognitivo** (Optimizado para RAG/Fine-tuning)

```json
{
  "document_title": "3 Pasos Contra el Sedentarismo",
  "document_summary": "Gu√≠a pr√°ctica para contrarrestar el sedentarismo mediante tres movimientos fundamentales que restauran la funcionalidad corporal natural: caminar m√°s para la capacidad cardiovascular base, sentarse en el suelo para movilidad de cadera, y colgarse para fuerza de agarre y descompresi√≥n espinal. El libro explica c√≥mo el sedentarismo causa adaptaciones corporales problem√°ticas y presenta una metodolog√≠a espec√≠fica basada en movimientos naturales para recuperar la salud y funcionalidad.",
  "detected_language": "es",
  
  "concepts": {
    "sedentarismo": {
      "concept_id": "sedentarismo",
      "name": "Sedentarismo",
      "definition": "Estado cr√≥nico de inactividad f√≠sica que resulta de la exposici√≥n prolongada a entornos que requieren poca o ninguna actividad f√≠sica, causando adaptaciones corporales que comprometen la salud y funcionalidad natural del cuerpo humano.",
      "first_mentioned_in": "introduccion",
      "relevant_sections": ["introduccion", "problemas_comunes", "tres_pasos"]
    },
    "movimiento_natural": {
      "concept_id": "movimiento_natural",
      "name": "Movimiento Natural", 
      "definition": "Patrones de movimiento para los que el cuerpo humano est√° evolutivamente adaptado, incluyendo caminar, sentarse en el suelo, colgarse y otras actividades que mantienen la funcionalidad corporal √≥ptima sin requerir equipamiento especializado.",
      "first_mentioned_in": "introduccion",
      "relevant_sections": ["introduccion", "tres_pasos"]
    },
    "vida_nomada": {
      "concept_id": "vida_nomada",
      "name": "Vida N√≥mada Ancestral",
      "definition": "Estilo de vida de nuestros ancestros durante m√°s de dos millones de a√±os, caracterizado por movimiento constante, variedad de posturas y est√≠mulos diversos que moldearon nuestro cuerpo para la adaptaci√≥n y resiliencia.",
      "first_mentioned_in": "introduccion",
      "relevant_sections": ["introduccion"]
    },
    "tres_pasos": {
      "concept_id": "tres_pasos",
      "name": "Metodolog√≠a de Tres Pasos",
      "definition": "Sistema espec√≠fico de intervenci√≥n contra el sedentarismo que consiste en: 1) Caminar m√°s para restaurar la funcionalidad base, 2) Sentarse m√°s en el suelo para recuperar movilidad de cadera, y 3) Colgarse m√°s de las manos para fortalecer agarre y descomprimir columna.",
      "first_mentioned_in": "tres_pasos",
      "relevant_sections": ["tres_pasos", "paso_1", "paso_2", "paso_3"]
    }
  },
  
  "hierarchical_summaries": {
    "book": {
      "section_id": "book",
      "title": "3 Pasos Contra el Sedentarismo",
      "summary": "Gu√≠a pr√°ctica para contrarrestar el sedentarismo mediante tres movimientos fundamentales que restauran la funcionalidad corporal natural. Explica c√≥mo el sedentarismo causa adaptaciones corporales problem√°ticas y presenta una metodolog√≠a espec√≠fica basada en movimientos naturales para recuperar la salud y funcionalidad.",
      "key_concepts": ["sedentarismo", "movimiento_natural", "vida_nomada", "tres_pasos"],
      "summary_length": 850
    },
    "introduccion": {
      "section_id": "introduccion",
      "title": "Introducci√≥n al sedentarismo",
      "summary": "An√°lisis profundo del sedentarismo como discrepancia entre nuestra biolog√≠a ancestral n√≥mada y el entorno moderno. Explica c√≥mo nuestros ancestros vivieron durante m√°s de dos millones de a√±os en movimiento constante, y c√≥mo la revoluci√≥n agr√≠cola hace 10,000 a√±os nos transform√≥ en seres sedentarios, creando un desajuste que genera enfermedades de la civilizaci√≥n y adaptaciones celulares problem√°ticas.",
      "key_concepts": ["sedentarismo", "vida_nomada", "movimiento_natural"],
      "summary_length": 780
    },
    "problemas_comunes": {
      "section_id": "problemas_comunes",
      "title": "Problemas comunes: limitaciones de la movilidad, dolor y estr√©s",
      "summary": "Exploraci√≥n cient√≠fica de c√≥mo el sistema nervioso procesa movimiento y dolor, explicando conceptos como propiocepci√≥n, mapas cerebrales, nocicepci√≥n y sensibilizaci√≥n. Analiza la relaci√≥n entre estabilidad del tronco y movilidad de extremidades, y c√≥mo la rigidez muscular act√∫a como mecanismo de protecci√≥n del cerebro ante movimientos percibidos como inseguros.",
      "key_concepts": ["dolor_cronico", "mapas_cerebrales", "estabilidad_proximal"],
      "summary_length": 720
    },
    "tres_pasos": {
      "section_id": "tres_pasos", 
      "title": "3 pasos para salir del sedentarismo",
      "summary": "Presentaci√≥n de la metodolog√≠a central: tres movimientos espec√≠ficos que abordan las causas ra√≠z del sedentarismo. Caminar m√°s como actividad natural accesible, sentarse m√°s en el suelo para fortalecer musculatura postural y movilidad de cadera, y colgarse m√°s de las manos para desarrollar agarre y descomprimir articulaciones. Incluye respiraci√≥n como herramienta para controlar el sistema nervioso aut√≥nomo.",
      "key_concepts": ["tres_pasos", "caminar", "sentarse_suelo", "colgarse", "respiracion"],
      "summary_length": 920
    },
    "paso_1": {
      "section_id": "paso_1",
      "title": "Caminar m√°s",
      "summary": "Explicaci√≥n de caminar como la actividad m√°s natural para el ser humano. No requiere equipo especial y es accesible para todos. Beneficios incluyen mejora de densidad √≥sea, circulaci√≥n, salud de los pies y activaci√≥n de m√∫sculos posturales. M√°s efectivo distribuir peque√±as caminatas a lo largo del d√≠a que hacer una sola caminata larga.",
      "key_concepts": ["caminar", "movimiento_base", "densidad_osea"],
      "summary_length": 650
    },
    "paso_2": {
      "section_id": "paso_2",
      "title": "Sentarse m√°s en el suelo",
      "summary": "An√°lisis de c√≥mo la silla proporciona estabilidad externa que atrofia la musculatura postural y reduce el rango de movimiento. Sentarse en el suelo obliga a usar m√∫sculos posturales, cambiar de postura constantemente y fortalecer articulaciones. Esta pr√°ctica mejora fuerza, equilibrio y movilidad del tren inferior, relacion√°ndose con mayor longevidad.",
      "key_concepts": ["sentarse_suelo", "musculatura_postural", "movilidad_cadera"],
      "summary_length": 680
    },
    "paso_3": {
      "section_id": "paso_3",
      "title": "Colgarse m√°s de las manos",
      "summary": "Como primates, estamos biol√≥gicamente dise√±ados para colgarnos. La falta de este movimiento debilita el agarre, tendones y ligamentos del tren superior, creando desequilibrios en hombros. Colgarse de forma progresiva fortalece el agarre, descomprime articulaciones y mejora movilidad y control de hombros y esc√°pulas.",
      "key_concepts": ["colgarse", "fuerza_agarre", "descompresion_articular"],
      "summary_length": 620
    }
  },
  
  "hierarchy_index": {
    "0": ["book"],
    "1": ["introduccion", "problemas_comunes", "tres_pasos", "conclusiones"],
    "2": ["paso_1", "paso_2", "paso_3", "paso_extra"]
  },
  
  "parent_child_map": {
    "book": ["introduccion", "problemas_comunes", "tres_pasos", "conclusiones"],
    "tres_pasos": ["paso_1", "paso_2", "paso_3", "paso_extra"]
  },
  
  "total_sections": 8,
  "avg_summary_length": 740,
  "total_concepts": 4
}
```

### **Schema JSON y Versionado**

**Estrategia de Versionado del Schema**: 
- Todo output sigue un **Schema JSON versionado** para seguridad del consumidor
- Las versiones del schema usan **versionado sem√°ntico** (MAJOR.MINOR.PATCH)
- Versi√≥n actual: **v1.0.0**

**Ubicaci√≥n del Schema**:
```
Repositorio GitHub: https://github.com/juanje/cognitive-document-reader/schemas/
‚îú‚îÄ‚îÄ v1.0.0/
‚îÇ   ‚îú‚îÄ‚îÄ cognitive-knowledge.json       # Schema principal de output
‚îÇ   ‚îú‚îÄ‚îÄ concept-definition.json        # Schema de concepto
‚îÇ   ‚îî‚îÄ‚îÄ section-summary.json          # Schema de resumen
‚îî‚îÄ‚îÄ README.md                          # Documentaci√≥n de schemas
```

**Uso para Consumidores**:
```python
# Ejemplo de validaci√≥n Python
import jsonschema
import requests

# Cargar schema desde GitHub
schema_url = "https://raw.githubusercontent.com/juanje/cognitive-document-reader/main/schemas/v1.0.0/cognitive-knowledge.json"
schema = requests.get(schema_url).json()

# Validar output del cognitive reader
jsonschema.validate(output_data, schema)
```

**Evoluci√≥n del Schema**:
- **v1.0.0**: Release inicial (res√∫menes jer√°rquicos + conceptos)
- **v1.1.0**: Futuro - A√±adir campos opcionales (compatible hacia atr√°s)
- **v2.0.0**: Futuro - Cambios breaking (bump de versi√≥n mayor)

**Output Incluye Versi√≥n del Schema**:
```json
{
  "schema_version": "1.0.0",
  "document_title": "...",
  ...
}
```

### **Markdown de Evoluci√≥n B√°sica** (Anotaciones simples)

```markdown
# 3 Pasos Contra el Sedentarismo - Resumen de Lectura Cognitiva

> **Procesamiento**: Lectura cognitiva de dos pasadas | 3 refinamientos | 5 enriquecimientos

## üìñ Resumen del Documento
Comprensi√≥n final enriquecida del documento completo...

## üìÑ Res√∫menes de Secciones

### Introducci√≥n al sedentarismo ‚ú® *Refinado + Enriquecido*
Resumen final que incorpora comprensi√≥n de secciones posteriores...

**Nota**: Este resumen fue refinado durante primera pasada cuando el m√©todo espec√≠fico de 3 pasos se volvi√≥ claro.

### Problemas comunes: limitaciones de la movilidad, dolor y estr√©s ‚ú® *Enriquecido*  
Resumen final enriquecido con contexto global sobre c√≥mo los problemas se conectan con soluciones...

**Nota**: Este resumen fue enriquecido durante segunda pasada con contexto completo del documento sobre los 3 pasos.

### 3 pasos para salir del sedentarismo ‚ú® *Refinado + Enriquecido*
Resumen final mostrando los tres movimientos espec√≠ficos (caminar m√°s, sentarse en el suelo, colgarse) como intervenci√≥n sistem√°tica...

**Nota**: Este resumen fue refinado durante primera pasada y enriquecido durante segunda pasada.

---

## üîÑ Notas de Procesamiento Cognitivo

**Refinamientos hechos durante primera pasada**: 3
- Introducci√≥n: Actualizado cuando las soluciones de movimiento espec√≠ficas se volvieron claras
- Secci√≥n 3 pasos: Actualizado cuando la conexi√≥n entre problemas y movimientos espec√≠ficos se volvi√≥ clara

**Enriquecimientos hechos durante segunda pasada**: 5  
- Todas las secciones enriquecidas con contexto completo del documento
- Conexiones entre problemas de movimiento y soluciones de movimiento espec√≠ficas se volvieron m√°s claras

**Insight clave**: El enfoque de dos pasadas revel√≥ la metodolog√≠a coherente del libro donde cada secci√≥n construye hacia la soluci√≥n espec√≠fica de 3 pasos (caminar m√°s, sentarse en el suelo, colgarse).
```

### **Salida CLI** (Mostrar diferencia)

```bash
$ cognitive-reader libro.md

‚úÖ Lectura Cognitiva Completa

üìä An√°lisis del Documento:
- Total secciones: 15
- Conceptos identificados: 12
- Longitud promedio de res√∫menes: 740 caracteres

üìÑ Salida guardada en: libro_resumen_cognitivo.json
```

---

## üß™ Requisitos de Desarrollo y Testing

### **Soporte de Modo de Desarrollo**

**Caracter√≠sticas de Desarrollo Requeridas**:
- **Modo dry-run**: Habilitar testing sin llamadas API LLM
- **Aislamiento de componentes**: Capacidad de probar primera pasada y segunda pasada independientemente
- **Toggles de caracter√≠sticas cognitivas**: Habilitar/deshabilitar refinamiento y segunda pasada por separado
- **Comparaci√≥n de rendimiento**: Comparar resultados de procesamiento cognitivo vs secuencial
- **M√©tricas de procesamiento**: Reporte claro de estad√≠sticas de procesamiento cognitivo

**Requisitos de Configuraci√≥n**:
- Todas las caracter√≠sticas cognitivas deben ser configurables v√≠a variables de entorno
- Debe soportar testing incremental de caracter√≠sticas (habilitar solo refinamiento, o solo segunda pasada)
- Debe proporcionar defaults amigables para desarrollo para testing
- Testing comprehensivo de configuraci√≥n de caracter√≠sticas cognitivas

### **Estrategia de Testing**

**Requisitos de Testing Funcional**:
- **Validaci√≥n de refinamiento**: Verificar que refinamientos mejoran calidad de comprensi√≥n
- **Validaci√≥n de enriquecimiento**: Verificar que segunda pasada a√±ade contexto significativo
- **Testing de modelo dual**: Validar modelo r√°pido para primera pasada, modelo de calidad para segunda pasada
- **Demostraci√≥n de beneficio cognitivo**: Mostrar diferencia clara entre enfoques

**Requisitos de Testing de Rendimiento**:
- **Uso de memoria**: Sin aumento significativo de memoria para caracter√≠sticas cognitivas b√°sicas
- **Optimizaci√≥n de llamadas LLM**: Reutilizaci√≥n eficiente de contexto a trav√©s de pasadas
- **Escalabilidad**: Rendimiento debe permanecer aceptable para documentos de gran tama√±o

**Requisitos de Aseguramiento de Calidad**:
- **Preservaci√≥n de voz del autor**: Procesamiento cognitivo debe mantener fidelidad de contenido
- **Validaci√≥n de coherencia**: Refinamientos y enriquecimientos deben mejorar coherencia
- **Testing de regresi√≥n**: Asegurar que caracter√≠sticas cognitivas no rompan funcionalidad existente
- **Manejo de casos extremos**: Manejar documentos donde refinamiento/enriquecimiento proporcionan valor m√≠nimo

---

## üéØ Fases de Desarrollo

### **Fundamentos: Modelo de Datos Cognitivos**

**Objetivos**:
- Implementar modelos de datos cognitivos completos
- Crear sistema de configuraci√≥n de caracter√≠sticas cognitivas
- Establecer fundaci√≥n para caracter√≠sticas cognitivas

**Entregables**:
- Modelo `SectionSummary` mejorado con seguimiento cognitivo
- Modelo `CognitiveKnowledge` actualizado con estad√≠sticas de procesamiento
- `CognitiveConfig` extendido con toggles de caracter√≠sticas cognitivas
- Testing completo de caracter√≠sticas cognitivas

### **Primera Pasada: Refinamiento Progresivo**

**Objetivos**:
- Implementar capacidad de refinamiento en lectura progresiva
- A√±adir detecci√≥n de refinamiento y actualizaci√≥n de res√∫menes
- Implementar detecci√≥n de refinamiento eficiente

**Entregables**:
- `ProgressiveReader` mejorado con capacidad de refinamiento
- Implementaci√≥n de algoritmo de detecci√≥n de refinamiento
- Configuraci√≥n de umbral de refinamiento
- Testing unitario para caracter√≠sticas de refinamiento

### **Segunda Pasada: Enriquecimiento Contextual**

**Objetivos**:
- Implementar capacidad de enriquecimiento con contexto global
- A√±adir procesamiento de segunda pasada al flujo principal de lectura
- Integrar resultados de primera pasada y segunda pasada

**Entregables**:
- Implementaci√≥n de componente `ContextualEnricher`
- Integraci√≥n de segunda pasada en flujo principal de lectura
- Detecci√≥n y seguimiento de enriquecimiento
- Testing completo de flujo de dos pasadas

### **Validaci√≥n: Testing y Optimizaci√≥n**

**Objetivos**:
- Validar beneficios de procesamiento cognitivo con documentos reales
- Testing de rendimiento y optimizaci√≥n
- Creaci√≥n de documentaci√≥n y ejemplos

**Entregables**:
- Formatos de salida actualizados con metadatos cognitivos
- Benchmarking de rendimiento con configuraciones de modelo dual
- Testing de validaci√≥n "3 pasos contra el sedentarismo"
- Documentaci√≥n de usuario y ejemplos
- Release MVP v2.0

---

## üìà M√©tricas de √âxito (Objetivos MVP)

### **Objetivos de Prueba de Concepto**
- ‚úÖ **Demostrar diferencia cognitiva**: Diferencia clara entre lectura cognitiva y procesamiento fragmentado tradicional
- ‚úÖ **Validaci√≥n de refinamiento**: Mostrar ejemplos donde comprensi√≥n mejor√≥ durante primera pasada  
- ‚úÖ **Validaci√≥n de enriquecimiento**: Mostrar ejemplos donde segunda pasada a√±adi√≥ valor
- ‚úÖ **Test "3 pasos"**: Procesar exitosamente cap√≠tulos de muestra con enfoque cognitivo
- ‚úÖ **Validaci√≥n de modelo dual**: Demostrar beneficios de estrategia modelo r√°pido/calidad

### **Requisitos T√©cnicos**
- ‚úÖ **API limpia**: Interfaz simple y enfocada para lectura cognitiva
- ‚úÖ **Optimizaci√≥n de rendimiento**: Estrategia efectiva de modelo dual para balance velocidad/calidad
- ‚úÖ **Eficiencia de memoria**: Procesamiento eficiente con m√∫ltiples configuraciones de modelo
- ‚úÖ **Amigable para desarrollo**: Opciones comprehensivas de dry-run y configuraci√≥n

### **Indicadores de Calidad**
- ‚úÖ **Refinamientos coherentes**: Refinamientos deben mejorar calidad de resumen
- ‚úÖ **Enriquecimientos valiosos**: Segunda pasada debe a√±adir contexto significativo
- ‚úÖ **Preservaci√≥n de voz del autor**: Mantener fidelidad al contenido original
- ‚úÖ **Calidad clara del output**: Res√∫menes y conceptos finales demuestran comprensi√≥n superior
- ‚úÖ **Efectividad de modelos**: Modelo r√°pido habilita velocidad, modelo de calidad mejora profundidad

---

## üìö Testing con Documento Real

### **Documento de Ejemplo para Validaci√≥n**

El proyecto incluye una versi√≥n reducida del libro real "3 pasos contra el sedentarismo" en `examples/3 pasos contra el sedentarismo.md` para habilitar **testing realista** y **validaci√≥n de calidad**.

#### **Estructura del Documento** (Contenido Real)
```
3 pasos contra el sedentarismo.md
‚îú‚îÄ‚îÄ Introducci√≥n al sedentarismo
‚îÇ   ‚îú‚îÄ‚îÄ ¬øQu√© es el sedentarismo?
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ De n√≥madas a sedentarios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Enfermedades de la civilizaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ En la especializaci√≥n est√° la clave
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Nuestras c√©lulas se adaptan
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Conclusiones
‚îú‚îÄ‚îÄ Problemas comunes: limitaciones de la movilidad, dolor y estr√©s
‚îÇ   ‚îú‚îÄ‚îÄ Sistema nervioso
‚îÇ   ‚îú‚îÄ‚îÄ Movilidad  
‚îÇ   ‚îî‚îÄ‚îÄ Dolor
‚îú‚îÄ‚îÄ 3 pasos para salir del sedentarismo
‚îÇ   ‚îú‚îÄ‚îÄ Caminar m√°s
‚îÇ   ‚îú‚îÄ‚îÄ Sentarse m√°s en el suelo
‚îÇ   ‚îú‚îÄ‚îÄ Colgarse m√°s de las manos
‚îÇ   ‚îú‚îÄ‚îÄ Paso extra: respiraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ ¬øY ahora qu√©? Siguientes pasos
‚îî‚îÄ‚îÄ Conclusiones
```

#### **Beneficios Clave para Testing**

1. **üéØ Contenido Aut√©ntico**: Voz y metodolog√≠a real del autor
2. **üî¨ Validaci√≥n de Calidad**: Comparar procesamiento cognitivo vs. tradicional
3. **üìä Extracci√≥n de Conceptos**: Validar extracci√≥n de t√©rminos espec√≠ficos del dominio
4. **üèóÔ∏è Testing de Jerarqu√≠a**: Estructura multinivel con relaciones l√≥gicas
5. **‚ö° Testing de Rendimiento**: Documento de tama√±o apropiado para testing realista pero manejable

#### **Casos de Prueba Recomendados**

```python
# Caso de Prueba 1: Procesamiento Cognitivo Completo
test_file = "examples/3 pasos contra el sedentarismo.md"
result = cognitive_reader.process_document(
    file_path=test_file,
    enable_second_pass=True,
    enable_refinement=True
)

# Validar que se extraen conceptos aut√©nticos
expected_concepts = [
    "sedentarismo", "vida_nomada", "movimiento_natural", 
    "tres_pasos", "dolor_cronico", "mapas_cerebrales"
]

# Caso de Prueba 2: Comparaci√≥n de Calidad
traditional_chunks = chunk_processor.process(test_file)
cognitive_summaries = result.hierarchical_summaries

# Los res√∫menes cognitivos deber√≠an mostrar:
# ‚úÖ Comprensi√≥n coherente de la metodolog√≠a
# ‚úÖ Progresi√≥n l√≥gica de problemas a soluciones  
# ‚úÖ Voz del autor y terminolog√≠a espec√≠fica preservada
# ‚úÖ Conceptos conectados entre secciones
```

#### **Indicadores de Calidad a Validar**

- **üìñ Resumen Coherente del Libro**: Debe capturar la metodolog√≠a central y progresi√≥n
- **üîó Conceptos Conectados**: La relaci√≥n `sedentarismo` ‚Üí `tres_pasos` debe ser clara
- **üéØ Terminolog√≠a Precisa**: T√©rminos espec√≠ficos como "propiocepci√≥n", "nocicepci√≥n" 
- **üìö Voz Preservada**: Mantiene el tono cient√≠fico pero accesible del autor
- **üß© Jerarqu√≠a L√≥gica**: Flujo Introducci√≥n ‚Üí Problemas ‚Üí Soluciones ‚Üí Conclusiones

---

## üöÄ Desarrollo Futuro (Post-MVP)

### **Caracter√≠sticas Cognitivas Avanzadas**
- **Lectura iterativa multi-pasada**: Extender m√°s all√° de 2 pasadas al procesamiento cognitivo de N pasadas
  - N√∫mero configurable de pasadas (3, 4, 5+ re-lecturas)
  - Cada pasada profundiza comprensi√≥n y refina conceptos iterativamente
  - Detecci√≥n de rendimientos decrecientes para optimizar n√∫mero de pasadas autom√°ticamente
  - Estrategias de prompting espec√≠ficas por pasada para refinamiento progresivo
  - Acumulaci√≥n avanzada de contexto a trav√©s de m√∫ltiples iteraciones
- **Detecci√≥n compleja de conceptos emergentes**: Patrones m√°s sofisticados de emergencia de conceptos
- **Generaci√≥n de grafo de conocimiento**: Exportar relaciones a bases de datos de grafos
- **S√≠ntesis cognitiva multi-documento**: Leer a trav√©s de documentos relacionados
- **Estrategias avanzadas de refinamiento**: Disparadores de refinamiento m√°s inteligentes

### **Integraci√≥n Avanzada**
- **Detecci√≥n de contradicciones**: Manejar inconsistencias inteligentemente  
- **Bucles de retroalimentaci√≥n experta**: Incorporar refinamientos de expertos humanos
- **Estrategias cognitivas adaptativas**: Ajustar enfoque basado en tipo de documento
- **Optimizaci√≥n de rendimiento**: Caching avanzado y procesamiento paralelo

---

## üí° Innovaci√≥n Clave del MVP v2

**Lectura Cognitiva M√≠nima**: El primer sistema en implementar **proceso b√°sico de lectura humana de dos pasadas** con:

1. ‚úÖ **Progresiva + Refinamiento**: Primera pasada que puede actualizar comprensi√≥n mientras crece el contexto
2. ‚úÖ **Enriquecimiento Global**: Segunda pasada que enriquece con contexto completo del documento  
3. ‚úÖ **Res√∫menes Integrados**: Output final que refleja comprensi√≥n profunda sin metadata de proceso
4. ‚úÖ **Prueba de Concepto**: Demostrar diferencia clara de fragmentaci√≥n basada en chunks

**MVP v2** prueba que **la lectura cognitiva funciona diferente** al procesamiento secuencial, estableciendo la fundaci√≥n para caracter√≠sticas cognitivas m√°s avanzadas en fases futuras.

---

*Esta especificaci√≥n define el sistema m√≠nimo viable de lectura cognitiva que demuestra evoluci√≥n de comprensi√≥n similar a la humana mientras mantiene simplicidad e implementabilidad.*
